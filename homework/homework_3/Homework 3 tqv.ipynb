{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "For this homework, you will be working extensively in tensorflow. It is suggested that you spin up a Google Cloud VM with a GPU attached. Remember, instructions for doing so are found in Homework 0.\n",
    "\n",
    "### Part 1: Homework 2, but on tensorflow\n",
    "### Part 2: DNN on MNIST and CIFAR10\n",
    "### Part 3: VGG on MNIST and CIFAR10\n",
    "### (Optional) Part 4, getting state of the art (#SOTA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "You don't have to repeat everything in homework 2, but rather pick one set of two features that worked well for you last homework, and implement logistic regression using tensorflow without using keras (you will practice using keras in parts 2 and 3). In other words, using tensorflow operations, please create a scalar-value loss function and let tensorflow create the training operation for logistic regression, which automatically computes the gradients and updates the weight parameters. Note that the logistic loss is a special case of the softmax cross entropy loss that you've seen when classifying MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "number_a = 6\n",
    "number_b = 9\n",
    "\n",
    "digit_a_indexes = np.where(digits.target==number_a) \n",
    "digit_b_indexes = np.where(digits.target==number_b)\n",
    "\n",
    "# Extract training and testing sets \n",
    "targets = np.concatenate((digits.target[digit_a_indexes], digits.target[digit_b_indexes]))\n",
    "images = np.concatenate((digits.images[digit_a_indexes], digits.images[digit_b_indexes]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(vector):\n",
    "    image = vector.reshape(8, 8) # get back original image shape\n",
    "    def compute_feature_a(image):\n",
    "        top = np.sum(image[0:3, :])\n",
    "\n",
    "        return top\n",
    "\n",
    "    def compute_feature_b(image):\n",
    "        bottom = np.sum(image[4:7, :])\n",
    "\n",
    "        return bottom\n",
    "    \n",
    "    return compute_feature_a(image), compute_feature_b(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply and plot features\n",
    "\n",
    "X_features = np.apply_along_axis(compute_features, 1,\n",
    "                                 X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "\n",
    "X_features_a = X_features[np.where(y_train==number_a)]\n",
    "X_features_b = X_features[np.where(y_train==number_b)]\n",
    "\n",
    "X_features_test = np.apply_along_axis(compute_features, 1,\n",
    "                                 X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(X_features_a[:, 0], X_features_a[:, 1], '.')\n",
    "plt.plot(X_features_b[:, 0], X_features_b[:, 1], '.')\n",
    "plt.legend([str(number_a), str(number_b)])\n",
    "plt.xlabel('feature_a')\n",
    "plt.ylabel('feature_b')\n",
    "plt.ylim(X_features[:, 1].min(), X_features[:, 1].max()) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(features_a, features_b, features, labels, weights, t=0):\n",
    "    \n",
    "    if weights.shape[0] == 2:\n",
    "        bound_x = (t-weights[1]*features[:,1])/(weights[0]+0.000001)\n",
    "    else: bound_x = (t-weights[2]*features[:,1] - weights[0])/(weights[1]+0.000001)\n",
    "    bound = np.c_[bound_x, features[:, 1]]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(features_a[:, 0], features_a[:, 1], '.')\n",
    "    plt.plot(features_b[:, 0], features_b[:, 1], '.')\n",
    "    plt.legend([str(number_b), str(number_a)])\n",
    "    plt.plot(bound[:, 0], bound[:, 1])\n",
    "    plt.xlabel('feature_a')\n",
    "    plt.ylabel('feature_b')\n",
    "    plt.ylim(features[:, 1].min(), features[:, 1].max()) \n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_arr = y_train.reshape([y_train.shape[0],1])\n",
    "logistic_y = np.copy(y_train_arr)\n",
    "logistic_y[y_train == number_a] = 0\n",
    "logistic_y[y_train == number_b] = 1\n",
    "\n",
    "y_test_arr = y_test.reshape([y_test.shape[0],1])\n",
    "logistic_y_test = np.copy(y_test_arr)\n",
    "logistic_y_test[y_test == number_a] = 0\n",
    "logistic_y_test[y_test == number_b] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Concat a row of one to feature vector to account for the bias\n",
    "X_features = np.c_[np.ones((X_features.shape[0], 1)), X_features]\n",
    "X_features_test = np.c_[np.ones((X_features_test.shape[0], 1)), X_features_test]\n",
    "\n",
    "# Create vars\n",
    "feature = tf.placeholder(dtype=tf.float32, shape=(None,X_features.shape[1]), name='X_feature')\n",
    "label = tf.placeholder(dtype=tf.int32, shape=(None,1), name='y')\n",
    "w = tf.get_variable(name='weight', dtype=tf.float32, shape=(X_features.shape[1],1), initializer=tf.random_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operations\n",
    "y_pred = tf.matmul(feature, w)\n",
    "loss = tf.losses.sigmoid_cross_entropy(label, y_pred)\n",
    "\n",
    "t_op = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.62321\n",
      "0.0047721495\n",
      "0.004771362\n",
      "0.0047705886\n",
      "0.004769826\n",
      "0.0047690757\n",
      "0.0047683427\n",
      "0.0047675944\n",
      "0.004766881\n",
      "0.004766177\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Start a session and initialize vars\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start training. First, choose number of iterations\n",
    "ITERATION = 2000\n",
    "for i in range(ITERATION):\n",
    "    sess.run(t_op, feed_dict={feature:X_features, label:logistic_y})\n",
    "    if i % (ITERATION/10) == 0:\n",
    "        print(sess.run(loss, feed_dict={feature:X_features, label:logistic_y}))\n",
    "#     print(sess.run(label, feed_dict={label:logistic_y}), sess.run(y_pred, feed_dict={feature:X_features}))\n",
    "\n",
    "pred = sess.run(y_pred, feed_dict={feature:X_features_test})\n",
    "t=0.5\n",
    "pred[pred<t] = 0\n",
    "pred[pred>t] = 1\n",
    "print(accuracy_score(logistic_y_test, pred))\n",
    "\n",
    "w_b = np.ones([3,])\n",
    "w_pred = sess.run(w)\n",
    "wcopy = np.copy(w_b)\n",
    "wcopy[0] = w_pred[0]\n",
    "wcopy[1] = w_pred[1]\n",
    "wcopy[2] = w_pred[2]\n",
    "\n",
    "# X_features_a = X_features_test[np.where(y_test==number_a)]\n",
    "# X_features_b = X_features_test[np.where(y_test==number_b)]\n",
    "visualize_model(X_features_a, X_features_b, X_features, y_train, wcopy, t=0.5)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2:  DNN on MNIST and CIFAR10\n",
    "\n",
    "In our lab, you guys saw how to work with the MNIST dataset to perform image classification. We can attempt the MNIST classification problem with just fully connected layers. This means we will be optimizing for non-banded matrices (no convolutions).\n",
    "\n",
    "1. Calcualte the number of weight parameters you are optimizing for 1, 2 and 3 differen fully connected layers (the total size of each layer is up to you).\n",
    "2. What is the max layer depth you can go before training loss does not converge? You can usually tell that something is not converging by examining the training loss vs. iteration curve.\n",
    "3. How does the number of parameters relate to the training loss and validation/test loss? Try to get a few data points to speak to this question.\n",
    "3. Keeping the maximum number of parameters possible while still maintaining convergence (i.e., a good training and validation/test loss), what happens when you swap the activation function to `tanh` instead of `relu`? How about `sigmoid`?\n",
    "4. After exploring the above, train a DNN model with the combination of hyperparameters that you believe will work best on MNIST.\n",
    "5. Using the same architecture, try training a DNN model on more difficult dataset such as Fashion MNIST or CIFAR10/100. Example download instructions are shown in the next problem.\n",
    "\n",
    "### Must haves\n",
    "1. Make a curve of the final validation/test loss of your DNN after the loss plateaus as a function of the number of weight parameters used (final loss versus # parameters used). Note that you might see something like the curve below for a low number of parameters, but as the number of parameters increases, it will not look like this plot. \n",
    "2. On the same figure, make the same curve as above, but use different activation functions in your architecture.\n",
    "3. Plot a point corresponding to your crafted DNN archiecture for question 4.\n",
    "4. Repeat 1-3 for CIFAR10\n",
    "\n",
    "The curves when reasonable # params are used look like the below\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.backend import clear_session\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = tf.keras.datasets.mnist.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[1].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "# Define function to return params count and minimum validation loss for each n_layer\n",
    "def params_valloss(n_layers, weights_layer=100, epoch=10, verbose=0, early_stop=False, activation='relu',\n",
    "                  input_shape=(28, 28, 1), lr=0.001):\n",
    "    params_count, min_val_loss = [], []\n",
    "    for i in range(1, n_layers+1):\n",
    "        # Build your DNN, an example model is given for you.\n",
    "        if early_stop:\n",
    "            es = EarlyStopping(restore_best_weights=True)\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "\n",
    "            # Try adding more layers and graph the final loss and accuracy\n",
    "        for j in range(i):\n",
    "            model.add(Dense(weights_layer, activation=activation))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=tf.train.AdamOptimizer(lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        # Count param\n",
    "        params_count.append(model.count_params())\n",
    "        \n",
    "        if early_stop:\n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  callbacks=[es],\n",
    "                  validation_data=(X_val, y_val))\n",
    "        else: \n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  validation_data=(X_val, y_val))\n",
    "\n",
    "        curr_l = hist.history['val_loss']\n",
    "        min_val_loss.append(curr_l[-1])\n",
    "        \n",
    "        del model\n",
    "        clear_session()  # Clear previous model\n",
    "        gc.collect()\n",
    "    return params_count, min_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 44,860\n",
      "Trainable params: 44,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Part 2.1\n",
    "n_layers = 3\n",
    "params_count, _ = params_valloss(n_layers, epoch=1, weights_layer=50)  # Calculate # of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters for 1 layer(s): 39760\n",
      "Number of parameters for 2 layer(s): 42310\n",
      "Number of parameters for 3 layer(s): 44860\n"
     ]
    }
   ],
   "source": [
    "# Print numbers of parameters\n",
    "for i in range(len(params_count)):\n",
    "    print('Number of parameters for ' + str(i+1) + ' layer(s): ' + str(params_count[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 109,810\n",
      "Trainable params: 109,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 119,910\n",
      "Trainable params: 119,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 130,010\n",
      "Trainable params: 130,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 140,110\n",
      "Trainable params: 140,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 150,210\n",
      "Trainable params: 150,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 160,310\n",
      "Trainable params: 160,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 170,410\n",
      "Trainable params: 170,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Part 2.2\n",
    "n_layers = 10\n",
    "epoch = 10\n",
    "\n",
    "# Get val_loss vs #params results for three types of activation. Early-stop is used to choose the optimal iteration for each \n",
    "# training, making sure that all the training have converged\n",
    "params_count_tanh, min_val_tanh = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, activation='tanh', \n",
    "                                                 early_stop=True)\n",
    "params_count, min_val_loss = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, early_stop=True)\n",
    "params_count_sig, min_val_sig = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, activation='sigmoid', \n",
    "                                               early_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_loss: 0.12849667707253248 at 160310 params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri Vu\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get minimum val loss and corresponded #param, indicating best model\n",
    "min_val = min([min(min_val_loss), min(min_val_tanh), min(min_val_sig)])\n",
    "if np.where(min_val_tanh==min_val)[0]:\n",
    "    min_params = params_count_tanh[np.asscalar(np.where(min_val_tanh==min_val)[0])]\n",
    "elif np.where(min_val_loss==min_val)[0]:\n",
    "    min_params = params_count[np.asscalar(np.where(min_val_loss==min_val)[0])]\n",
    "elif np.where(min_val_sig==min_val)[0]:\n",
    "    min_params = params_count_sig[np.asscalar(np.where(min_val_sig==min_val)[0])]\n",
    "    \n",
    "print('Best val_loss: ' + str(min_val) + ' at ' + str(min_params) + ' params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out results\n",
    "plt.plot(params_count, min_val_loss, \"r-+\", linewidth=2)\n",
    "plt.plot(params_count, min_val_tanh, \"g-*\", linewidth=2)\n",
    "plt.plot(params_count_sig, min_val_sig, \"o-\", linewidth=2)\n",
    "plt.plot(min_params, min_val, \"p\", markersize=12)\n",
    "plt.legend(['relu', 'tanh', 'sigmoid', 'Best model'])\n",
    "plt.xlabel('#params')\n",
    "plt.ylabel('Minimum Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On both training data, ReLU has the best performance. Sigmoid and tanh have good starting points but overfit faster with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (50000, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CIFAR-10\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_val = X_val.reshape(X_val.shape[0], 32, 32, 3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(32, 32, 3));\n",
    "ax2.imshow(X_train[1].reshape(32, 32, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 318,410\n",
      "Trainable params: 318,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 328,510\n",
      "Trainable params: 328,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 348,710\n",
      "Trainable params: 348,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 358,810\n",
      "Trainable params: 358,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 368,910\n",
      "Trainable params: 368,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 379,010\n",
      "Trainable params: 379,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 389,110\n",
      "Trainable params: 389,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 399,210\n",
      "Trainable params: 399,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 318,410\n",
      "Trainable params: 318,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 328,510\n",
      "Trainable params: 328,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 348,710\n",
      "Trainable params: 348,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 358,810\n",
      "Trainable params: 358,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 368,910\n",
      "Trainable params: 368,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 379,010\n",
      "Trainable params: 379,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 389,110\n",
      "Trainable params: 389,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 399,210\n",
      "Trainable params: 399,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 318,410\n",
      "Trainable params: 318,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 328,510\n",
      "Trainable params: 328,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 348,710\n",
      "Trainable params: 348,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 358,810\n",
      "Trainable params: 358,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 368,910\n",
      "Trainable params: 368,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 379,010\n",
      "Trainable params: 379,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 389,110\n",
      "Trainable params: 389,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 399,210\n",
      "Trainable params: 399,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_layers = 10\n",
    "epoch = 10\n",
    "\n",
    "# Get val_loss vs #params results for three types of activation. Early-stop is used to choose the optimal iteration for each \n",
    "# training, making sure that all the training have converged\n",
    "params_count, min_val_loss = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, early_stop=False,\n",
    "                                           input_shape=(32, 32, 3), lr=1e-4)\n",
    "params_count_tanh, min_val_tanh = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, activation='tanh', \n",
    "                                                 early_stop=False, input_shape=(32, 32, 3), lr=1e-5)\n",
    "params_count_sig, min_val_sig = params_valloss(n_layers, epoch=epoch, verbose=0, weights_layer=100, activation='sigmoid', \n",
    "                                               early_stop=False, input_shape=(32, 32, 3), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_loss: 1.5683327753067016 at 399210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tri Vu\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get minimum val loss\n",
    "min_val = min([min(min_val_loss), min(min_val_tanh), min(min_val_sig)])\n",
    "if np.where(min_val_tanh==min_val)[0]:\n",
    "    min_params = params_count_tanh[np.asscalar(np.where(min_val_tanh==min_val)[0])]\n",
    "elif np.where(min_val_loss==min_val)[0]:\n",
    "    min_params = params_count[np.asscalar(np.where(min_val_loss==min_val)[0])]\n",
    "elif np.where(min_val_sig==min_val)[0]:\n",
    "    min_params = params_count_sig[np.asscalar(np.where(min_val_sig==min_val)[0])]\n",
    "    \n",
    "print('Best val_loss: ' + str(min_val) + ' at ' + str(min_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(params_count, min_val_loss, \"r-+\", linewidth=2)\n",
    "plt.plot(params_count, min_val_tanh, \"g-*\", linewidth=2)\n",
    "plt.plot(params_count_sig, min_val_sig, \"o-\", linewidth=2)\n",
    "plt.plot(min_params, min_val, \"p\", markersize=12)\n",
    "plt.legend(['relu', 'tanh', 'sigmoid', 'Best model'])\n",
    "plt.xlabel('#params')\n",
    "plt.ylabel('Minimum Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. VGG on CIFAR100 and CIFAR10\n",
    "\n",
    "VGG is a simple, but powerful CNN created in 2015. Read the VGG paper here: https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "Here, we're going to try to reproduce the model's findings on the cifar10 and cifar100 dataset. Note that the paper takes 224 x 224 images, but cifar10 and 100 are only 32 x 32 images.\n",
    "\n",
    "1. Implement all of the layers for the VGG ConvNet Configuration A. Please use the shell code below as guide. Then, train this network on the Cifar10 and Cifar100 datasets.\n",
    "2. For Cifar10 and 100, VGG is probably overkill. Try changing the number of layers and number of filters without sacrificing too much performance accuracy. How many filters can you get rid of before you see the accuracy drop by more than 2%? Where in the architecture is it better to remove filters - towards the input layers, or more towards the output layers?\n",
    "3. For what you experiment with--report the parameter, validation loss curves for changing the number of i) layers, ii) filter size, iii) both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (50000, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the same model in the other notebook, looks very simplified.\n",
    "import tensorflow as tf\n",
    "(X_train10, y_train10), (X_val10, y_val10) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train10 = tf.keras.utils.to_categorical(y_train10, 10)\n",
    "y_val10 = tf.keras.utils.to_categorical(y_val10, 10)\n",
    "\n",
    "X_train10 = X_train10.reshape(X_train10.shape[0], 32, 32, 3)\n",
    "X_val10 = X_val10.reshape(X_val10.shape[0], 32, 32, 3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train10.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train10[0].reshape(32, 32, 3));\n",
    "ax2.imshow(X_train10[1].reshape(32, 32, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 28,144,010\n",
      "Trainable params: 28,144,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 1.5198 - acc: 0.4412 - val_loss: 1.2080 - val_acc: 0.5628\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 1.0667 - acc: 0.6183 - val_loss: 1.0465 - val_acc: 0.6323\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.8414 - acc: 0.7050 - val_loss: 0.8786 - val_acc: 0.6941\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.6607 - acc: 0.7725 - val_loss: 0.8359 - val_acc: 0.7179\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.4909 - acc: 0.8288 - val_loss: 0.8982 - val_acc: 0.7065\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.3606 - acc: 0.8744 - val_loss: 0.9090 - val_acc: 0.7211\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.2545 - acc: 0.9120 - val_loss: 0.9561 - val_acc: 0.7332\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.1953 - acc: 0.9334 - val_loss: 1.0341 - val_acc: 0.7272\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.1454 - acc: 0.9495 - val_loss: 1.1891 - val_acc: 0.7236\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.1273 - acc: 0.9568 - val_loss: 1.1439 - val_acc: 0.7287\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.1017 - acc: 0.9652 - val_loss: 1.2239 - val_acc: 0.7313\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0906 - acc: 0.9694 - val_loss: 1.2627 - val_acc: 0.7339\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0882 - acc: 0.9704 - val_loss: 1.2193 - val_acc: 0.7357\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0838 - acc: 0.9714 - val_loss: 1.2677 - val_acc: 0.7251\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0730 - acc: 0.9755 - val_loss: 1.2657 - val_acc: 0.7412\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0660 - acc: 0.9782 - val_loss: 1.2459 - val_acc: 0.7340\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0675 - acc: 0.9773 - val_loss: 1.2468 - val_acc: 0.7311\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0591 - acc: 0.9807 - val_loss: 1.2526 - val_acc: 0.7325\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0595 - acc: 0.9803 - val_loss: 1.3259 - val_acc: 0.7338\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0592 - acc: 0.9806 - val_loss: 1.3672 - val_acc: 0.7368\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0532 - acc: 0.9824 - val_loss: 1.3997 - val_acc: 0.7326\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0463 - acc: 0.9844 - val_loss: 1.4091 - val_acc: 0.7472\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0525 - acc: 0.9831 - val_loss: 1.2993 - val_acc: 0.7406\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0455 - acc: 0.9853 - val_loss: 1.3998 - val_acc: 0.7340\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0470 - acc: 0.9847 - val_loss: 1.4218 - val_acc: 0.7376\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0435 - acc: 0.9854 - val_loss: 1.3363 - val_acc: 0.7394\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0450 - acc: 0.9853 - val_loss: 1.5044 - val_acc: 0.7456\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0424 - acc: 0.9861 - val_loss: 1.4845 - val_acc: 0.7397\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0375 - acc: 0.9879 - val_loss: 1.4389 - val_acc: 0.7375\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0382 - acc: 0.9873 - val_loss: 1.5514 - val_acc: 0.7403\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0387 - acc: 0.9875 - val_loss: 1.4898 - val_acc: 0.7465\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0382 - acc: 0.9878 - val_loss: 1.4641 - val_acc: 0.7376\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0342 - acc: 0.9891 - val_loss: 1.4018 - val_acc: 0.7480\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0343 - acc: 0.9889 - val_loss: 1.4520 - val_acc: 0.7412\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0332 - acc: 0.9898 - val_loss: 1.5498 - val_acc: 0.7473\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0342 - acc: 0.9892 - val_loss: 1.5305 - val_acc: 0.7386\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0313 - acc: 0.9900 - val_loss: 1.5492 - val_acc: 0.7359\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0373 - acc: 0.9885 - val_loss: 1.5368 - val_acc: 0.7390\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0313 - acc: 0.9905 - val_loss: 1.3957 - val_acc: 0.7438\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0331 - acc: 0.9894 - val_loss: 1.6315 - val_acc: 0.7371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0336 - acc: 0.9896 - val_loss: 1.5969 - val_acc: 0.7462\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 1.4288 - val_acc: 0.7419\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0289 - acc: 0.9907 - val_loss: 1.6455 - val_acc: 0.7374\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 1.5884 - val_acc: 0.7493\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0269 - acc: 0.9914 - val_loss: 1.6421 - val_acc: 0.7466\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0319 - acc: 0.9901 - val_loss: 1.7624 - val_acc: 0.7469\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0259 - acc: 0.9920 - val_loss: 1.6969 - val_acc: 0.7484\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0329 - acc: 0.9901 - val_loss: 1.5347 - val_acc: 0.7433\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 1.6080 - val_acc: 0.7439\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.0274 - acc: 0.9915 - val_loss: 1.5918 - val_acc: 0.7520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model10 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model10.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model10.summary()\n",
    "hist = model10.fit(X_train10, y_train10,\n",
    "                  batch_size=64,\n",
    "                  epochs=50,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val10, y_val10))\n",
    "\n",
    "del model10\n",
    "clear_session()  # Clear previous model\n",
    "gc.collect()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VGG-A on cifar10: 75.2%\n"
     ]
    }
   ],
   "source": [
    "# Predict and get accuracy\n",
    "cifar10_accu = hist.history['val_acc'][-1]\n",
    "print('Accuracy of VGG-A on cifar10: ' + str(cifar10_accu*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (50000, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CIFAR 100 - Setup\n",
    "(X_train100, y_train100), (X_val100, y_val100) = tf.keras.datasets.cifar100.load_data()\n",
    "y_train100 = tf.keras.utils.to_categorical(y_train100, 100)\n",
    "y_val100 = tf.keras.utils.to_categorical(y_val100, 100)\n",
    "\n",
    "X_train100 = X_train100.reshape(X_train100.shape[0], 32, 32, 3)\n",
    "X_val100 = X_val100.reshape(X_val100.shape[0], 32, 32, 3)\n",
    "\n",
    "print('Training data shape', X_train100.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train100[0].reshape(32, 32, 3));\n",
    "ax2.imshow(X_train100[1].reshape(32, 32, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 28,512,740\n",
      "Trainable params: 28,512,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 25s 508us/step - loss: 3.8512 - acc: 0.1029 - val_loss: 3.4990 - val_acc: 0.1607\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 3.1510 - acc: 0.2189 - val_loss: 2.9525 - val_acc: 0.2671\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 2.7063 - acc: 0.3063 - val_loss: 2.6856 - val_acc: 0.3165\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 24s 474us/step - loss: 2.3309 - acc: 0.3832 - val_loss: 2.5116 - val_acc: 0.3595\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 1.9654 - acc: 0.4624 - val_loss: 2.4296 - val_acc: 0.3826\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 1.5863 - acc: 0.5543 - val_loss: 2.4196 - val_acc: 0.3931\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 1.2076 - acc: 0.6449 - val_loss: 2.5136 - val_acc: 0.4094\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.8623 - acc: 0.7366 - val_loss: 2.9068 - val_acc: 0.3986\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 24s 474us/step - loss: 0.6072 - acc: 0.8091 - val_loss: 3.2191 - val_acc: 0.3931\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.4344 - acc: 0.8587 - val_loss: 3.6487 - val_acc: 0.4003\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.3504 - acc: 0.8873 - val_loss: 3.7214 - val_acc: 0.3966\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.2802 - acc: 0.9094 - val_loss: 3.9306 - val_acc: 0.3981\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.2376 - acc: 0.9234 - val_loss: 4.0668 - val_acc: 0.3888\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.2155 - acc: 0.9306 - val_loss: 4.1357 - val_acc: 0.3956\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.1980 - acc: 0.9368 - val_loss: 4.3144 - val_acc: 0.3903\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1822 - acc: 0.9424 - val_loss: 4.2108 - val_acc: 0.3928\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1744 - acc: 0.9454 - val_loss: 4.1189 - val_acc: 0.3925\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.1635 - acc: 0.9485 - val_loss: 4.1153 - val_acc: 0.3980\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.1533 - acc: 0.9520 - val_loss: 4.3368 - val_acc: 0.3956\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.1467 - acc: 0.9541 - val_loss: 4.3455 - val_acc: 0.3920\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1485 - acc: 0.9518 - val_loss: 4.2187 - val_acc: 0.4047\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.1313 - acc: 0.9591 - val_loss: 4.4719 - val_acc: 0.4014\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.1255 - acc: 0.9602 - val_loss: 4.3492 - val_acc: 0.3926\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.1207 - acc: 0.9624 - val_loss: 4.4499 - val_acc: 0.3987\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.1217 - acc: 0.9625 - val_loss: 4.5341 - val_acc: 0.3984\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1182 - acc: 0.9630 - val_loss: 4.3562 - val_acc: 0.4073\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1103 - acc: 0.9651 - val_loss: 4.4200 - val_acc: 0.4051\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.1159 - acc: 0.9637 - val_loss: 4.6116 - val_acc: 0.4038\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.1150 - acc: 0.9647 - val_loss: 4.2760 - val_acc: 0.4018\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.0994 - acc: 0.9687 - val_loss: 4.4983 - val_acc: 0.4050\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0924 - acc: 0.9709 - val_loss: 4.7634 - val_acc: 0.3977\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.1114 - acc: 0.9654 - val_loss: 4.5007 - val_acc: 0.3894\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0955 - acc: 0.9707 - val_loss: 4.7490 - val_acc: 0.4001\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 470us/step - loss: 0.0864 - acc: 0.9728 - val_loss: 4.5772 - val_acc: 0.3942\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.0970 - acc: 0.9703 - val_loss: 4.5811 - val_acc: 0.3917\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0970 - acc: 0.9709 - val_loss: 4.3789 - val_acc: 0.3965\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0844 - acc: 0.9746 - val_loss: 4.3289 - val_acc: 0.4063\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0836 - acc: 0.9745 - val_loss: 4.8292 - val_acc: 0.4001\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 24s 470us/step - loss: 0.0880 - acc: 0.9729 - val_loss: 4.3908 - val_acc: 0.4039\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 24s 474us/step - loss: 0.0846 - acc: 0.9744 - val_loss: 4.4555 - val_acc: 0.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0820 - acc: 0.9750 - val_loss: 4.5759 - val_acc: 0.4018\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0792 - acc: 0.9760 - val_loss: 4.4488 - val_acc: 0.4050\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0810 - acc: 0.9750 - val_loss: 4.4613 - val_acc: 0.3998\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0826 - acc: 0.9752 - val_loss: 4.4925 - val_acc: 0.4010\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.0765 - acc: 0.9764 - val_loss: 4.5700 - val_acc: 0.4011\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0773 - acc: 0.9762 - val_loss: 4.4530 - val_acc: 0.4000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0738 - acc: 0.9778 - val_loss: 4.7323 - val_acc: 0.4052\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0687 - acc: 0.9787 - val_loss: 4.5592 - val_acc: 0.4015\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0727 - acc: 0.9784 - val_loss: 4.4560 - val_acc: 0.4011\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 24s 474us/step - loss: 0.0743 - acc: 0.9777 - val_loss: 4.4722 - val_acc: 0.4042\n"
     ]
    }
   ],
   "source": [
    "# Train model on cifar 100\n",
    "model100 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "model100.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model100.summary()\n",
    "hist = model100.fit(X_train100, y_train100,\n",
    "                  batch_size=64,\n",
    "                  epochs=50,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val100, y_val100))\n",
    "\n",
    "del model100\n",
    "clear_session()  # Clear previous model\n",
    "gc.collect()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VGG-A on cifar100: 40.42%\n"
     ]
    }
   ],
   "source": [
    "# Predict and get accuracy\n",
    "cifar100_accu = hist.history['val_acc'][-1]\n",
    "print('Accuracy of VGG-A on cifar100: ' + str(cifar100_accu*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The extremely high training accuracy (~99% for cifar-10 and ~98% for cifar-100) and the low validation accuracy (~75% for cifar-10 and ~40% for cifar-100) show that the VGG-A model severely overfits both cifar-10 and -100 data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine how many cn layer we can remove before accuracy drops by 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify layers toward the input (convolutional layer)\n",
    "def modified_cn_vggA(X_train, y_train, X_val, y_val, layers, compa, ini_filter=64, input_shape=(32, 32, 3), \n",
    "                  classes=10, epoch=5, batch_size=64, early_stop=True, verbose=1):\n",
    "    \n",
    "    params_count, min_val_loss, min_val_acc = [], [], []\n",
    "    for i in range(layers, 0, -1):  # Number of layers is decremented to see at which # of layers, accuracy will drop by 2%\n",
    "        clear_session()\n",
    "        \n",
    "        if early_stop:\n",
    "            es = EarlyStopping(restore_best_weights=True)\n",
    "            \n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter, (3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "        \n",
    "        if i>7:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*2, (3,3), padding='same', activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        if i>6:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*4, (3,3), padding='same', activation='relu'))\n",
    "        if i>5:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*4, (3,3), padding='same', activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        if i>4:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        if i>3:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "            \n",
    "        if i>2:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        if i>1:\n",
    "            model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        # Count param\n",
    "        params_count.append(model.count_params())\n",
    "        \n",
    "        if early_stop:\n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  callbacks=[es],\n",
    "                  validation_data=(X_val, y_val))\n",
    "        else: \n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  validation_data=(X_val, y_val))\n",
    "        \n",
    "        if compa-hist.history['val_acc'][-1]>0.02:\n",
    "            print('At ' + str(layers) + ' layers and ' + str(ini_filter) + ' initial filters, accuracy starts to drop by more than 2%')\n",
    "        \n",
    "        curr_l = hist.history['val_loss']\n",
    "        min_val_loss.append(curr_l[-1])\n",
    "        min_val_acc.append(hist.history['val_acc'][-1])\n",
    "        \n",
    "        del model\n",
    "    return params_count, min_val_loss, min_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       147712    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 34,214,154\n",
      "Trainable params: 34,214,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 1.5030 - acc: 0.4657 - val_loss: 1.1734 - val_acc: 0.5775\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.9851 - acc: 0.6519 - val_loss: 0.9173 - val_acc: 0.6860\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.7494 - acc: 0.7384 - val_loss: 0.7763 - val_acc: 0.7320\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.5569 - acc: 0.8051 - val_loss: 0.7824 - val_acc: 0.7402\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.3984 - acc: 0.8611 - val_loss: 0.7755 - val_acc: 0.7638\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.2602 - acc: 0.9106 - val_loss: 0.8845 - val_acc: 0.7492\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.1781 - acc: 0.9384 - val_loss: 0.8951 - val_acc: 0.7609\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.1350 - acc: 0.9528 - val_loss: 1.0036 - val_acc: 0.7564\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.1054 - acc: 0.9644 - val_loss: 1.0369 - val_acc: 0.7554\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0931 - acc: 0.9690 - val_loss: 1.0061 - val_acc: 0.7678\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0831 - acc: 0.9723 - val_loss: 1.1333 - val_acc: 0.7633\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0769 - acc: 0.9745 - val_loss: 1.0659 - val_acc: 0.7716\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0731 - acc: 0.9751 - val_loss: 1.2115 - val_acc: 0.7499\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0668 - acc: 0.9777 - val_loss: 1.1150 - val_acc: 0.7533\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0593 - acc: 0.9806 - val_loss: 1.1838 - val_acc: 0.7660\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0576 - acc: 0.9814 - val_loss: 1.1771 - val_acc: 0.7709\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 601us/step - loss: 0.0562 - acc: 0.9819 - val_loss: 1.1490 - val_acc: 0.7707\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0495 - acc: 0.9839 - val_loss: 1.2945 - val_acc: 0.7622\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 602us/step - loss: 0.0516 - acc: 0.9831 - val_loss: 1.1179 - val_acc: 0.7696\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 602us/step - loss: 0.0446 - acc: 0.9858 - val_loss: 1.2323 - val_acc: 0.7714\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0468 - acc: 0.9840 - val_loss: 1.2576 - val_acc: 0.7703\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0448 - acc: 0.9858 - val_loss: 1.2819 - val_acc: 0.7676\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0419 - acc: 0.9860 - val_loss: 1.2490 - val_acc: 0.7691\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0408 - acc: 0.9868 - val_loss: 1.2385 - val_acc: 0.7709\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0345 - acc: 0.9887 - val_loss: 1.2507 - val_acc: 0.7668\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0369 - acc: 0.9878 - val_loss: 1.3482 - val_acc: 0.7744\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0338 - acc: 0.9892 - val_loss: 1.4246 - val_acc: 0.7728\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0351 - acc: 0.9889 - val_loss: 1.3231 - val_acc: 0.7715\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0349 - acc: 0.9889 - val_loss: 1.2617 - val_acc: 0.7770\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0339 - acc: 0.9889 - val_loss: 1.2600 - val_acc: 0.7815\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0315 - acc: 0.9897 - val_loss: 1.2515 - val_acc: 0.7741\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0319 - acc: 0.9900 - val_loss: 1.3058 - val_acc: 0.7774\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0284 - acc: 0.9908 - val_loss: 1.4444 - val_acc: 0.7761\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0310 - acc: 0.9896 - val_loss: 1.4543 - val_acc: 0.7673\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0289 - acc: 0.9909 - val_loss: 1.3235 - val_acc: 0.7812\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0263 - acc: 0.9915 - val_loss: 1.2963 - val_acc: 0.7708\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0263 - acc: 0.9912 - val_loss: 1.4289 - val_acc: 0.7628\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0260 - acc: 0.9914 - val_loss: 1.3570 - val_acc: 0.7839\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0243 - acc: 0.9921 - val_loss: 1.4206 - val_acc: 0.7723\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0282 - acc: 0.9908 - val_loss: 1.4142 - val_acc: 0.7807\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0253 - acc: 0.9923 - val_loss: 1.5329 - val_acc: 0.7660\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0261 - acc: 0.9917 - val_loss: 1.3991 - val_acc: 0.7718\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0222 - acc: 0.9926 - val_loss: 1.4305 - val_acc: 0.7712\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 1.3712 - val_acc: 0.7860\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0256 - acc: 0.9918 - val_loss: 1.5308 - val_acc: 0.7690\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0252 - acc: 0.9924 - val_loss: 1.4024 - val_acc: 0.7781\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0218 - acc: 0.9933 - val_loss: 1.4065 - val_acc: 0.7817\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0214 - acc: 0.9933 - val_loss: 1.5715 - val_acc: 0.7729\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0240 - acc: 0.9926 - val_loss: 1.5154 - val_acc: 0.7858\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 1.3505 - val_acc: 0.7850\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       147712    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,624,074\n",
      "Trainable params: 33,624,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0215 - acc: 0.9933 - val_loss: 1.5688 - val_acc: 0.7604\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0205 - acc: 0.9939 - val_loss: 1.4883 - val_acc: 0.7810\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 1.3565 - val_acc: 0.7850\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0209 - acc: 0.9939 - val_loss: 1.6254 - val_acc: 0.7769\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0175 - acc: 0.9946 - val_loss: 1.7241 - val_acc: 0.7750\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0195 - acc: 0.9941 - val_loss: 1.6161 - val_acc: 0.7794\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 1.5381 - val_acc: 0.7852\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0185 - acc: 0.9947 - val_loss: 1.3981 - val_acc: 0.7817\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0189 - acc: 0.9941 - val_loss: 1.6165 - val_acc: 0.7779\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0190 - acc: 0.9941 - val_loss: 1.6318 - val_acc: 0.7639\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0181 - acc: 0.9939 - val_loss: 1.7723 - val_acc: 0.7787\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0195 - acc: 0.9943 - val_loss: 1.6306 - val_acc: 0.7804\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0182 - acc: 0.9944 - val_loss: 1.4481 - val_acc: 0.7769\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0202 - acc: 0.9939 - val_loss: 1.6316 - val_acc: 0.7691\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 1.6314 - val_acc: 0.7831\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0210 - acc: 0.9938 - val_loss: 1.5419 - val_acc: 0.7860\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 1.5849 - val_acc: 0.7726\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0191 - acc: 0.9943 - val_loss: 1.6036 - val_acc: 0.7848\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0158 - acc: 0.9956 - val_loss: 1.7284 - val_acc: 0.7813\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0214 - acc: 0.9940 - val_loss: 1.4037 - val_acc: 0.7814\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0154 - acc: 0.9954 - val_loss: 1.5669 - val_acc: 0.7831\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0178 - acc: 0.9947 - val_loss: 1.4989 - val_acc: 0.7792\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 1.7136 - val_acc: 0.7778\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0169 - acc: 0.9953 - val_loss: 1.5739 - val_acc: 0.7731\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0198 - acc: 0.9947 - val_loss: 1.5998 - val_acc: 0.7766\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0175 - acc: 0.9954 - val_loss: 1.4313 - val_acc: 0.7845\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0176 - acc: 0.9949 - val_loss: 1.6820 - val_acc: 0.7869\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0159 - acc: 0.9956 - val_loss: 1.3504 - val_acc: 0.7765\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0119 - acc: 0.9966 - val_loss: 1.6177 - val_acc: 0.7854\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0201 - acc: 0.9940 - val_loss: 1.5621 - val_acc: 0.7847\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 31s 614us/step - loss: 0.0144 - acc: 0.9958 - val_loss: 1.4893 - val_acc: 0.7791\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0174 - acc: 0.9951 - val_loss: 1.4039 - val_acc: 0.7764\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0160 - acc: 0.9952 - val_loss: 1.5398 - val_acc: 0.7759\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0165 - acc: 0.9954 - val_loss: 1.6361 - val_acc: 0.7851\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 1.7360 - val_acc: 0.7717\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 1.4180 - val_acc: 0.7729\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 1.6174 - val_acc: 0.7812\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0154 - acc: 0.9956 - val_loss: 1.4592 - val_acc: 0.7816\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0196 - acc: 0.9945 - val_loss: 1.3665 - val_acc: 0.7823\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 1.5807 - val_acc: 0.7848\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0168 - acc: 0.9951 - val_loss: 1.5145 - val_acc: 0.7825\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0141 - acc: 0.9961 - val_loss: 1.4580 - val_acc: 0.7743\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0137 - acc: 0.9958 - val_loss: 1.5074 - val_acc: 0.7776\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0166 - acc: 0.9952 - val_loss: 1.2779 - val_acc: 0.7878\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 1.6577 - val_acc: 0.7756\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 1.6331 - val_acc: 0.7870\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 1.7350 - val_acc: 0.7725\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0151 - acc: 0.9955 - val_loss: 1.4500 - val_acc: 0.7816\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0123 - acc: 0.9965 - val_loss: 1.5950 - val_acc: 0.7820\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0148 - acc: 0.9961 - val_loss: 1.4532 - val_acc: 0.7845\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 57,757,450\n",
      "Trainable params: 57,757,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 615us/step - loss: 0.0122 - acc: 0.9967 - val_loss: 1.5085 - val_acc: 0.7860\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0141 - acc: 0.9962 - val_loss: 1.4266 - val_acc: 0.7938\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 1.6070 - val_acc: 0.7825\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0144 - acc: 0.9961 - val_loss: 1.5839 - val_acc: 0.7814\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0111 - acc: 0.9968 - val_loss: 1.6239 - val_acc: 0.7829\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 1.6104 - val_acc: 0.7644\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 1.5547 - val_acc: 0.7822\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0115 - acc: 0.9970 - val_loss: 1.4971 - val_acc: 0.7836\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0153 - acc: 0.9957 - val_loss: 1.5606 - val_acc: 0.7757\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0104 - acc: 0.9970 - val_loss: 1.5712 - val_acc: 0.7901\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0108 - acc: 0.9969 - val_loss: 1.8103 - val_acc: 0.7650\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0157 - acc: 0.9951 - val_loss: 1.4885 - val_acc: 0.7926\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0125 - acc: 0.9967 - val_loss: 1.5363 - val_acc: 0.7915\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 1.5378 - val_acc: 0.7857\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0135 - acc: 0.9966 - val_loss: 1.4846 - val_acc: 0.7894\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0114 - acc: 0.9968 - val_loss: 1.6186 - val_acc: 0.7798\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0104 - acc: 0.9972 - val_loss: 1.6411 - val_acc: 0.7774\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0169 - acc: 0.9953 - val_loss: 1.5480 - val_acc: 0.7760\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 1.6891 - val_acc: 0.7845\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0136 - acc: 0.9962 - val_loss: 1.7421 - val_acc: 0.7818\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0123 - acc: 0.9964 - val_loss: 1.5385 - val_acc: 0.7918\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0082 - acc: 0.9975 - val_loss: 1.7762 - val_acc: 0.7743\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0166 - acc: 0.9951 - val_loss: 1.6801 - val_acc: 0.7804\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0100 - acc: 0.9972 - val_loss: 1.5960 - val_acc: 0.7848\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0111 - acc: 0.9971 - val_loss: 1.7113 - val_acc: 0.7862\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0117 - acc: 0.9967 - val_loss: 1.5484 - val_acc: 0.7855\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0067 - acc: 0.9982 - val_loss: 1.5697 - val_acc: 0.7880\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 1.6562 - val_acc: 0.7813\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 1.6491 - val_acc: 0.7893\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 1.8405 - val_acc: 0.7922\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0128 - acc: 0.9968 - val_loss: 1.6055 - val_acc: 0.7841\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 1.6568 - val_acc: 0.7866\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 1.7198 - val_acc: 0.7770\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0126 - acc: 0.9963 - val_loss: 1.5826 - val_acc: 0.7896\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0113 - acc: 0.9969 - val_loss: 1.6269 - val_acc: 0.7839\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0100 - acc: 0.9973 - val_loss: 1.5152 - val_acc: 0.7873\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0093 - acc: 0.9977 - val_loss: 1.4595 - val_acc: 0.7939\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0104 - acc: 0.9972 - val_loss: 1.5248 - val_acc: 0.7797\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0150 - acc: 0.9959 - val_loss: 1.5406 - val_acc: 0.7882\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 1.5223 - val_acc: 0.7875\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 1.6490 - val_acc: 0.7882\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0110 - acc: 0.9971 - val_loss: 1.8034 - val_acc: 0.7794\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0122 - acc: 0.9965 - val_loss: 1.4940 - val_acc: 0.7870\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 1.6645 - val_acc: 0.7847\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0132 - acc: 0.9965 - val_loss: 1.5633 - val_acc: 0.7921\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 1.5962 - val_acc: 0.7830\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0098 - acc: 0.9971 - val_loss: 1.7283 - val_acc: 0.7854\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0129 - acc: 0.9966 - val_loss: 1.5858 - val_acc: 0.7716\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0092 - acc: 0.9976 - val_loss: 1.7025 - val_acc: 0.7782\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 1.5980 - val_acc: 0.7953\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 55,397,642\n",
      "Trainable params: 55,397,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0096 - acc: 0.9975 - val_loss: 1.5043 - val_acc: 0.7869\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0076 - acc: 0.9979 - val_loss: 1.6514 - val_acc: 0.7956\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0163 - acc: 0.9960 - val_loss: 1.6323 - val_acc: 0.7926\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 1.5136 - val_acc: 0.7815\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0075 - acc: 0.9980 - val_loss: 1.8599 - val_acc: 0.7859\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0092 - acc: 0.9978 - val_loss: 1.5772 - val_acc: 0.7867\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0130 - acc: 0.9965 - val_loss: 1.6959 - val_acc: 0.7876\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0104 - acc: 0.9970 - val_loss: 1.7089 - val_acc: 0.7875\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0101 - acc: 0.9977 - val_loss: 1.7067 - val_acc: 0.7841\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0105 - acc: 0.9972 - val_loss: 1.5683 - val_acc: 0.7834\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 1.7710 - val_acc: 0.7828\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0162 - acc: 0.9955 - val_loss: 1.4842 - val_acc: 0.7874\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 1.6268 - val_acc: 0.7868\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 1.9259 - val_acc: 0.7826\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0132 - acc: 0.9965 - val_loss: 1.5068 - val_acc: 0.7778\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0109 - acc: 0.9975 - val_loss: 1.7052 - val_acc: 0.7837\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0087 - acc: 0.9979 - val_loss: 1.6549 - val_acc: 0.7920\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0117 - acc: 0.9970 - val_loss: 1.6594 - val_acc: 0.7915\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0088 - acc: 0.9974 - val_loss: 1.5894 - val_acc: 0.7883\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0064 - acc: 0.9980 - val_loss: 1.6658 - val_acc: 0.7908\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 1.6225 - val_acc: 0.7818\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0184 - acc: 0.9956 - val_loss: 1.6506 - val_acc: 0.7866\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0076 - acc: 0.9980 - val_loss: 1.6405 - val_acc: 0.7895\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 1.5903 - val_acc: 0.7899\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0078 - acc: 0.9979 - val_loss: 1.7425 - val_acc: 0.7822\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0104 - acc: 0.9973 - val_loss: 1.5782 - val_acc: 0.7957\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 1.9834 - val_acc: 0.7775\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 1.8969 - val_acc: 0.7843\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 1.6366 - val_acc: 0.7853\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.7397 - val_acc: 0.7801\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0110 - acc: 0.9971 - val_loss: 1.5865 - val_acc: 0.7792\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 1.6740 - val_acc: 0.7879\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0084 - acc: 0.9977 - val_loss: 1.5845 - val_acc: 0.7854\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0084 - acc: 0.9978 - val_loss: 1.6005 - val_acc: 0.7868\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0143 - acc: 0.9964 - val_loss: 1.5031 - val_acc: 0.7904\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 1.6676 - val_acc: 0.7930\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0080 - acc: 0.9980 - val_loss: 1.6525 - val_acc: 0.7881\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0093 - acc: 0.9974 - val_loss: 1.7797 - val_acc: 0.7842\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0095 - acc: 0.9973 - val_loss: 1.8028 - val_acc: 0.7910\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 1.6438 - val_acc: 0.7819\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0096 - acc: 0.9974 - val_loss: 1.6984 - val_acc: 0.7773\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0066 - acc: 0.9983 - val_loss: 1.5635 - val_acc: 0.7829\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0119 - acc: 0.9967 - val_loss: 1.4563 - val_acc: 0.7818\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 1.9723 - val_acc: 0.7847\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0076 - acc: 0.9979 - val_loss: 1.9248 - val_acc: 0.7805\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 0.0135 - acc: 0.9962 - val_loss: 1.8827 - val_acc: 0.7626\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0100 - acc: 0.9973 - val_loss: 1.5182 - val_acc: 0.7938\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0059 - acc: 0.9984 - val_loss: 1.7533 - val_acc: 0.7943\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0064 - acc: 0.9986 - val_loss: 1.6617 - val_acc: 0.7897\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0155 - acc: 0.9961 - val_loss: 1.7950 - val_acc: 0.7890\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 153,701,130\n",
      "Trainable params: 153,701,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 1.8312 - val_acc: 0.7821\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 1.7150 - val_acc: 0.7793\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0106 - acc: 0.9969 - val_loss: 1.6152 - val_acc: 0.7894\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0059 - acc: 0.9985 - val_loss: 1.6725 - val_acc: 0.7893\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 1.9300 - val_acc: 0.7878\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 1.8832 - val_acc: 0.7793\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 1.6865 - val_acc: 0.7885\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0105 - acc: 0.9974 - val_loss: 1.7160 - val_acc: 0.7724\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0039 - acc: 0.9990 - val_loss: 1.6547 - val_acc: 0.7861\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0091 - acc: 0.9979 - val_loss: 1.6219 - val_acc: 0.8010\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 1.6437 - val_acc: 0.7889\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0076 - acc: 0.9981 - val_loss: 1.8530 - val_acc: 0.7655\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0102 - acc: 0.9975 - val_loss: 1.6808 - val_acc: 0.7978\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 1.6086 - val_acc: 0.7870\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0085 - acc: 0.9978 - val_loss: 1.7290 - val_acc: 0.7928\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0030 - acc: 0.9993 - val_loss: 1.7698 - val_acc: 0.7986\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0056 - acc: 0.9986 - val_loss: 1.7536 - val_acc: 0.7872\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 1.8754 - val_acc: 0.7835\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 1.7526 - val_acc: 0.7969\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 1.7949 - val_acc: 0.7852\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 1.6244 - val_acc: 0.7876\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 1.9938 - val_acc: 0.7749\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0140 - acc: 0.9966 - val_loss: 1.8373 - val_acc: 0.7923\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 1.7671 - val_acc: 0.7937\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 1.7207 - val_acc: 0.7898\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0128 - acc: 0.9967 - val_loss: 1.7225 - val_acc: 0.7842\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0050 - acc: 0.9988 - val_loss: 1.7931 - val_acc: 0.7939\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0109 - acc: 0.9974 - val_loss: 1.5082 - val_acc: 0.7877\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0141 - acc: 0.9963 - val_loss: 1.5563 - val_acc: 0.7902\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 1.7660 - val_acc: 0.7883\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0105 - acc: 0.9975 - val_loss: 1.6644 - val_acc: 0.7887\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 6.1489e-04 - acc: 0.9999 - val_loss: 1.9105 - val_acc: 0.7981\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.4650e-04 - acc: 1.0000 - val_loss: 1.9936 - val_acc: 0.7999\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 3.2409e-04 - acc: 1.0000 - val_loss: 2.0136 - val_acc: 0.7996\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2326e-04 - acc: 1.0000 - val_loss: 2.0377 - val_acc: 0.8000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2293e-04 - acc: 1.0000 - val_loss: 2.0671 - val_acc: 0.8001\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2274e-04 - acc: 1.0000 - val_loss: 2.1016 - val_acc: 0.8006\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2264e-04 - acc: 1.0000 - val_loss: 2.1374 - val_acc: 0.8007\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2257e-04 - acc: 1.0000 - val_loss: 2.1733 - val_acc: 0.8001\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2254e-04 - acc: 1.0000 - val_loss: 2.2090 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2251e-04 - acc: 1.0000 - val_loss: 2.2436 - val_acc: 0.8008\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2250e-04 - acc: 1.0000 - val_loss: 2.2841 - val_acc: 0.8009\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2249e-04 - acc: 1.0000 - val_loss: 2.3124 - val_acc: 0.8013\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 3.2249e-04 - acc: 1.0000 - val_loss: 2.3348 - val_acc: 0.8013\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.3583 - val_acc: 0.8009\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.3754 - val_acc: 0.8013\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.3910 - val_acc: 0.8014\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4018 - val_acc: 0.8014\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4132 - val_acc: 0.8015\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4219 - val_acc: 0.8012\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 151,341,322\n",
      "Trainable params: 151,341,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 616us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4305 - val_acc: 0.8012\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4364 - val_acc: 0.8006\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4419 - val_acc: 0.8006\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4465 - val_acc: 0.8008\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4495 - val_acc: 0.8007\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4521 - val_acc: 0.8008\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4535 - val_acc: 0.8007\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4547 - val_acc: 0.8010\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4558 - val_acc: 0.8009\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4541 - val_acc: 0.8001\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 83,937,034\n",
      "Trainable params: 83,937,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 614us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 2.4548 - val_acc: 0.8003\n"
     ]
    }
   ],
   "source": [
    "# For cifar10\n",
    "layers = 7  # Maximum amount of cn layers is 7\n",
    "cifar10_accu = 0.752\n",
    "params_count_layer10, min_val_loss_layer10, _ = modified_cn_vggA(X_train10, y_train10, X_val10, y_val10, layers, ini_filter=64, \n",
    "                                              input_shape=(32, 32, 3), classes=10, epoch=50, batch_size=64, \n",
    "                                              early_stop=False, verbose=1, compa=cifar10_accu)\n",
    "\n",
    "# Save the results to .txt file so we don't have to re-train the model\n",
    "np.savetxt(r\"cn_cifar10\" + \".txt\", np.asmatrix([params_count_layer10, min_val_loss_layer10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       147712    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 34,582,884\n",
      "Trainable params: 34,582,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 3.7348 - acc: 0.1321 - val_loss: 3.2286 - val_acc: 0.2171\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 2.8778 - acc: 0.2808 - val_loss: 2.6424 - val_acc: 0.3346\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 2.3492 - acc: 0.3890 - val_loss: 2.4630 - val_acc: 0.3689\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 1.8726 - acc: 0.4945 - val_loss: 2.2545 - val_acc: 0.4223\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 1.3787 - acc: 0.6116 - val_loss: 2.2094 - val_acc: 0.4478\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.8569 - acc: 0.7445 - val_loss: 2.6107 - val_acc: 0.4348\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.4568 - acc: 0.8590 - val_loss: 3.1235 - val_acc: 0.4385\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.2907 - acc: 0.9099 - val_loss: 3.3274 - val_acc: 0.4369\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.2186 - acc: 0.9335 - val_loss: 3.4140 - val_acc: 0.4308\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.1911 - acc: 0.9414 - val_loss: 3.7352 - val_acc: 0.4261\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.1623 - acc: 0.9503 - val_loss: 3.7103 - val_acc: 0.4364\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.1480 - acc: 0.9566 - val_loss: 3.6482 - val_acc: 0.4319\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.1432 - acc: 0.9572 - val_loss: 4.1848 - val_acc: 0.4259\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.1308 - acc: 0.9606 - val_loss: 3.9303 - val_acc: 0.4326\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.1251 - acc: 0.9634 - val_loss: 3.9076 - val_acc: 0.4401\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.1177 - acc: 0.9650 - val_loss: 4.2114 - val_acc: 0.4203\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.1113 - acc: 0.9667 - val_loss: 3.9386 - val_acc: 0.4376\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0963 - acc: 0.9717 - val_loss: 4.1661 - val_acc: 0.4286\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0936 - acc: 0.9722 - val_loss: 4.2719 - val_acc: 0.4341\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0996 - acc: 0.9711 - val_loss: 4.2341 - val_acc: 0.4291\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0930 - acc: 0.9723 - val_loss: 4.2348 - val_acc: 0.4318\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0900 - acc: 0.9731 - val_loss: 4.6337 - val_acc: 0.4213\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0844 - acc: 0.9754 - val_loss: 4.2059 - val_acc: 0.4349\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0785 - acc: 0.9768 - val_loss: 4.2224 - val_acc: 0.4297\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0839 - acc: 0.9757 - val_loss: 4.2252 - val_acc: 0.4315\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0805 - acc: 0.9770 - val_loss: 4.4557 - val_acc: 0.4274\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0703 - acc: 0.9796 - val_loss: 4.3504 - val_acc: 0.4381\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0729 - acc: 0.9783 - val_loss: 4.2911 - val_acc: 0.4314\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0748 - acc: 0.9775 - val_loss: 4.3286 - val_acc: 0.4307\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0711 - acc: 0.9799 - val_loss: 4.4689 - val_acc: 0.4345\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0621 - acc: 0.9820 - val_loss: 4.5596 - val_acc: 0.4289\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0694 - acc: 0.9795 - val_loss: 4.6618 - val_acc: 0.4332\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0669 - acc: 0.9800 - val_loss: 4.5775 - val_acc: 0.4227\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0555 - acc: 0.9842 - val_loss: 4.5348 - val_acc: 0.4309\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0553 - acc: 0.9841 - val_loss: 4.7232 - val_acc: 0.4260\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0631 - acc: 0.9819 - val_loss: 4.5850 - val_acc: 0.4338\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0601 - acc: 0.9829 - val_loss: 4.6313 - val_acc: 0.4287\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0558 - acc: 0.9844 - val_loss: 4.3491 - val_acc: 0.4334\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0510 - acc: 0.9853 - val_loss: 4.5069 - val_acc: 0.4355\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0638 - acc: 0.9813 - val_loss: 4.6617 - val_acc: 0.4324\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0566 - acc: 0.9840 - val_loss: 4.7333 - val_acc: 0.4316\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0476 - acc: 0.9858 - val_loss: 4.8204 - val_acc: 0.4314\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0516 - acc: 0.9843 - val_loss: 4.7082 - val_acc: 0.4236\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0515 - acc: 0.9850 - val_loss: 4.7183 - val_acc: 0.4301\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0469 - acc: 0.9864 - val_loss: 4.8694 - val_acc: 0.4264\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0521 - acc: 0.9850 - val_loss: 4.8792 - val_acc: 0.4178\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0509 - acc: 0.9855 - val_loss: 5.0274 - val_acc: 0.4348\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0496 - acc: 0.9854 - val_loss: 4.7799 - val_acc: 0.4314\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0465 - acc: 0.9861 - val_loss: 4.6497 - val_acc: 0.4311\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0457 - acc: 0.9869 - val_loss: 4.6775 - val_acc: 0.4184\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       147712    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 33,992,804\n",
      "Trainable params: 33,992,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 617us/step - loss: 0.0485 - acc: 0.9867 - val_loss: 4.9392 - val_acc: 0.4276\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0404 - acc: 0.9884 - val_loss: 4.9208 - val_acc: 0.4298\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0437 - acc: 0.9878 - val_loss: 5.0561 - val_acc: 0.4357\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0447 - acc: 0.9876 - val_loss: 4.7894 - val_acc: 0.4299\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0422 - acc: 0.9875 - val_loss: 4.9714 - val_acc: 0.4329\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0416 - acc: 0.9880 - val_loss: 4.9096 - val_acc: 0.4333\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0433 - acc: 0.9876 - val_loss: 5.0388 - val_acc: 0.4269\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0447 - acc: 0.9881 - val_loss: 4.6538 - val_acc: 0.4366\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0389 - acc: 0.9888 - val_loss: 5.0134 - val_acc: 0.4213\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0420 - acc: 0.9880 - val_loss: 4.7656 - val_acc: 0.4291\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0355 - acc: 0.9895 - val_loss: 5.2807 - val_acc: 0.4292\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0480 - acc: 0.9863 - val_loss: 4.8026 - val_acc: 0.4305\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0370 - acc: 0.9894 - val_loss: 5.1947 - val_acc: 0.4204\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0466 - acc: 0.9873 - val_loss: 4.9934 - val_acc: 0.4334\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0343 - acc: 0.9900 - val_loss: 5.0541 - val_acc: 0.4368\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0382 - acc: 0.9899 - val_loss: 4.8430 - val_acc: 0.4265\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0356 - acc: 0.9894 - val_loss: 5.0900 - val_acc: 0.4343\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0427 - acc: 0.9874 - val_loss: 5.0888 - val_acc: 0.4358\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0366 - acc: 0.9894 - val_loss: 5.1578 - val_acc: 0.4364\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0379 - acc: 0.9894 - val_loss: 5.0713 - val_acc: 0.4274\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0334 - acc: 0.9908 - val_loss: 5.3365 - val_acc: 0.4270\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0387 - acc: 0.9882 - val_loss: 4.9718 - val_acc: 0.4270\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0357 - acc: 0.9901 - val_loss: 5.1173 - val_acc: 0.4227\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0308 - acc: 0.9920 - val_loss: 5.4824 - val_acc: 0.4272\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0457 - acc: 0.9874 - val_loss: 5.3255 - val_acc: 0.4290\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0382 - acc: 0.9899 - val_loss: 5.0688 - val_acc: 0.4272\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0352 - acc: 0.9899 - val_loss: 5.2573 - val_acc: 0.4250\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0338 - acc: 0.9909 - val_loss: 5.2490 - val_acc: 0.4430\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0344 - acc: 0.9905 - val_loss: 5.1647 - val_acc: 0.4337\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0333 - acc: 0.9913 - val_loss: 5.0022 - val_acc: 0.4328\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0291 - acc: 0.9918 - val_loss: 5.5620 - val_acc: 0.4214\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0439 - acc: 0.9873 - val_loss: 5.4048 - val_acc: 0.4250\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0282 - acc: 0.9921 - val_loss: 5.5941 - val_acc: 0.4292\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0293 - acc: 0.9909 - val_loss: 5.5436 - val_acc: 0.4313\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0266 - acc: 0.9923 - val_loss: 5.4405 - val_acc: 0.4308\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0405 - acc: 0.9890 - val_loss: 5.2253 - val_acc: 0.4314\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0361 - acc: 0.9909 - val_loss: 5.3885 - val_acc: 0.4284\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0299 - acc: 0.9915 - val_loss: 5.3311 - val_acc: 0.4362\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0324 - acc: 0.9909 - val_loss: 5.3444 - val_acc: 0.4288\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0237 - acc: 0.9933 - val_loss: 5.5621 - val_acc: 0.4236\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0414 - acc: 0.9889 - val_loss: 5.4011 - val_acc: 0.4301\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0264 - acc: 0.9936 - val_loss: 5.3869 - val_acc: 0.4342\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0324 - acc: 0.9909 - val_loss: 5.3289 - val_acc: 0.4308\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0351 - acc: 0.9903 - val_loss: 5.6724 - val_acc: 0.4338\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0318 - acc: 0.9910 - val_loss: 5.4569 - val_acc: 0.4312\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 602us/step - loss: 0.0334 - acc: 0.9908 - val_loss: 5.6982 - val_acc: 0.4232\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0320 - acc: 0.9916 - val_loss: 5.2977 - val_acc: 0.4350\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0348 - acc: 0.9905 - val_loss: 5.3926 - val_acc: 0.4398\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0315 - acc: 0.9917 - val_loss: 5.4644 - val_acc: 0.4266\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0289 - acc: 0.9919 - val_loss: 5.5976 - val_acc: 0.4263\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 58,126,180\n",
      "Trainable params: 58,126,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0280 - acc: 0.9918 - val_loss: 5.4554 - val_acc: 0.4328\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0280 - acc: 0.9921 - val_loss: 5.7976 - val_acc: 0.4170\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0312 - acc: 0.9911 - val_loss: 5.6598 - val_acc: 0.4342\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0279 - acc: 0.9921 - val_loss: 5.5488 - val_acc: 0.4325\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0266 - acc: 0.9927 - val_loss: 5.4427 - val_acc: 0.4223\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0306 - acc: 0.9916 - val_loss: 5.7175 - val_acc: 0.4276\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0272 - acc: 0.9926 - val_loss: 5.5359 - val_acc: 0.4266\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0351 - acc: 0.9907 - val_loss: 5.4644 - val_acc: 0.4319\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0305 - acc: 0.9915 - val_loss: 5.5613 - val_acc: 0.4386\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0250 - acc: 0.9930 - val_loss: 5.5566 - val_acc: 0.4330\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0269 - acc: 0.9926 - val_loss: 5.5557 - val_acc: 0.4332\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0322 - acc: 0.9915 - val_loss: 5.7551 - val_acc: 0.4296\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0292 - acc: 0.9920 - val_loss: 5.7238 - val_acc: 0.4250\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0261 - acc: 0.9927 - val_loss: 5.7915 - val_acc: 0.4304\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0316 - acc: 0.9913 - val_loss: 5.5742 - val_acc: 0.4407\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0277 - acc: 0.9929 - val_loss: 5.8802 - val_acc: 0.4232\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0274 - acc: 0.9927 - val_loss: 5.6886 - val_acc: 0.4229\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0264 - acc: 0.9932 - val_loss: 5.7414 - val_acc: 0.4319\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0250 - acc: 0.9934 - val_loss: 5.7285 - val_acc: 0.4322\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0327 - acc: 0.9913 - val_loss: 5.7316 - val_acc: 0.4277\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0252 - acc: 0.9934 - val_loss: 6.0348 - val_acc: 0.4281\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0350 - acc: 0.9909 - val_loss: 5.5138 - val_acc: 0.4336\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0258 - acc: 0.9929 - val_loss: 5.7635 - val_acc: 0.4324\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0237 - acc: 0.9936 - val_loss: 5.7567 - val_acc: 0.4285\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0273 - acc: 0.9931 - val_loss: 5.8693 - val_acc: 0.4275\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0295 - acc: 0.9925 - val_loss: 5.8273 - val_acc: 0.4299\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0296 - acc: 0.9920 - val_loss: 6.0245 - val_acc: 0.4267\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0253 - acc: 0.9933 - val_loss: 5.8503 - val_acc: 0.4310\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0201 - acc: 0.9947 - val_loss: 5.9580 - val_acc: 0.4281\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0347 - acc: 0.9914 - val_loss: 5.7380 - val_acc: 0.4348\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0299 - acc: 0.9926 - val_loss: 5.7012 - val_acc: 0.4326\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0291 - acc: 0.9924 - val_loss: 5.9008 - val_acc: 0.4305\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0271 - acc: 0.9930 - val_loss: 5.9209 - val_acc: 0.4313\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0289 - acc: 0.9925 - val_loss: 5.7809 - val_acc: 0.4355\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0269 - acc: 0.9931 - val_loss: 5.9236 - val_acc: 0.4209\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0275 - acc: 0.9931 - val_loss: 5.5890 - val_acc: 0.4324\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0222 - acc: 0.9940 - val_loss: 5.6029 - val_acc: 0.4293\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0271 - acc: 0.9929 - val_loss: 5.5744 - val_acc: 0.4269\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0182 - acc: 0.9949 - val_loss: 5.6559 - val_acc: 0.4365\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0252 - acc: 0.9934 - val_loss: 5.8610 - val_acc: 0.4299\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0254 - acc: 0.9934 - val_loss: 5.6854 - val_acc: 0.4355\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0294 - acc: 0.9922 - val_loss: 5.8154 - val_acc: 0.4328\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0262 - acc: 0.9932 - val_loss: 5.8814 - val_acc: 0.4301\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0246 - acc: 0.9934 - val_loss: 6.0467 - val_acc: 0.4275\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0272 - acc: 0.9930 - val_loss: 5.9565 - val_acc: 0.4268\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0289 - acc: 0.9930 - val_loss: 6.1349 - val_acc: 0.4216\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0204 - acc: 0.9944 - val_loss: 6.2316 - val_acc: 0.4352\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0298 - acc: 0.9925 - val_loss: 6.2819 - val_acc: 0.4269\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0391 - acc: 0.9906 - val_loss: 5.9014 - val_acc: 0.4285\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0224 - acc: 0.9940 - val_loss: 6.2115 - val_acc: 0.4307\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 55,766,372\n",
      "Trainable params: 55,766,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0231 - acc: 0.9939 - val_loss: 6.0608 - val_acc: 0.4256\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0234 - acc: 0.9940 - val_loss: 6.0199 - val_acc: 0.4360\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0216 - acc: 0.9943 - val_loss: 5.9998 - val_acc: 0.4173\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0300 - acc: 0.9920 - val_loss: 6.1651 - val_acc: 0.4304\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0255 - acc: 0.9940 - val_loss: 6.1111 - val_acc: 0.4279\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0233 - acc: 0.9940 - val_loss: 6.0280 - val_acc: 0.4295\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0268 - acc: 0.9929 - val_loss: 6.0206 - val_acc: 0.4313\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0223 - acc: 0.9940 - val_loss: 6.0983 - val_acc: 0.4263\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0228 - acc: 0.9938 - val_loss: 6.3235 - val_acc: 0.4212\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0293 - acc: 0.9928 - val_loss: 6.2003 - val_acc: 0.4298\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0303 - acc: 0.9926 - val_loss: 6.1432 - val_acc: 0.4261\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0234 - acc: 0.9936 - val_loss: 6.0921 - val_acc: 0.4315\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0225 - acc: 0.9944 - val_loss: 5.9952 - val_acc: 0.4313\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0256 - acc: 0.9934 - val_loss: 6.3404 - val_acc: 0.4226\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0246 - acc: 0.9943 - val_loss: 6.2765 - val_acc: 0.4260\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0315 - acc: 0.9926 - val_loss: 6.4322 - val_acc: 0.4334\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0228 - acc: 0.9942 - val_loss: 6.4223 - val_acc: 0.4178\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0323 - acc: 0.9925 - val_loss: 6.6468 - val_acc: 0.4184\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0329 - acc: 0.9924 - val_loss: 6.2044 - val_acc: 0.4263\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0228 - acc: 0.9940 - val_loss: 6.4024 - val_acc: 0.4217\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0206 - acc: 0.9946 - val_loss: 6.4160 - val_acc: 0.4196\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0304 - acc: 0.9929 - val_loss: 6.4094 - val_acc: 0.4260\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0235 - acc: 0.9943 - val_loss: 6.5630 - val_acc: 0.4234\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0309 - acc: 0.9925 - val_loss: 6.4714 - val_acc: 0.4163\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0278 - acc: 0.9933 - val_loss: 6.1971 - val_acc: 0.4261\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0203 - acc: 0.9946 - val_loss: 6.2103 - val_acc: 0.4254\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0290 - acc: 0.9927 - val_loss: 6.1531 - val_acc: 0.4257\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0243 - acc: 0.9939 - val_loss: 6.3210 - val_acc: 0.4255\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0227 - acc: 0.9945 - val_loss: 6.5785 - val_acc: 0.4247\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0282 - acc: 0.9934 - val_loss: 6.2824 - val_acc: 0.4248\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0193 - acc: 0.9947 - val_loss: 6.4842 - val_acc: 0.4336\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0337 - acc: 0.9918 - val_loss: 6.6785 - val_acc: 0.4308\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0262 - acc: 0.9934 - val_loss: 6.2166 - val_acc: 0.4184\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0221 - acc: 0.9947 - val_loss: 6.4506 - val_acc: 0.4279\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0268 - acc: 0.9940 - val_loss: 6.2080 - val_acc: 0.4228\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0244 - acc: 0.9941 - val_loss: 6.3435 - val_acc: 0.4295\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0246 - acc: 0.9942 - val_loss: 6.5133 - val_acc: 0.4272\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0280 - acc: 0.9931 - val_loss: 6.1160 - val_acc: 0.4276\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0261 - acc: 0.9939 - val_loss: 6.3102 - val_acc: 0.4317\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0221 - acc: 0.9943 - val_loss: 6.6458 - val_acc: 0.4269\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0310 - acc: 0.9929 - val_loss: 6.3285 - val_acc: 0.4250\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0285 - acc: 0.9934 - val_loss: 6.5423 - val_acc: 0.4298\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0232 - acc: 0.9946 - val_loss: 6.4602 - val_acc: 0.4165\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0236 - acc: 0.9946 - val_loss: 6.4672 - val_acc: 0.4364\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0305 - acc: 0.9931 - val_loss: 6.5575 - val_acc: 0.4237\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0277 - acc: 0.9939 - val_loss: 6.5440 - val_acc: 0.4295\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0245 - acc: 0.9947 - val_loss: 6.3671 - val_acc: 0.4238\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0274 - acc: 0.9929 - val_loss: 6.5144 - val_acc: 0.4228\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0227 - acc: 0.9944 - val_loss: 6.5337 - val_acc: 0.4282\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0267 - acc: 0.9939 - val_loss: 6.5574 - val_acc: 0.4234\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 154,069,860\n",
      "Trainable params: 154,069,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0265 - acc: 0.9937 - val_loss: 6.5186 - val_acc: 0.4245\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0310 - acc: 0.9934 - val_loss: 6.6013 - val_acc: 0.4222\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0249 - acc: 0.9946 - val_loss: 6.3292 - val_acc: 0.4268\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0269 - acc: 0.9937 - val_loss: 6.6582 - val_acc: 0.4204\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0253 - acc: 0.9939 - val_loss: 6.6857 - val_acc: 0.4260\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0247 - acc: 0.9942 - val_loss: 6.7006 - val_acc: 0.4292\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0258 - acc: 0.9937 - val_loss: 6.9410 - val_acc: 0.4189\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0270 - acc: 0.9941 - val_loss: 6.5951 - val_acc: 0.4258\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0295 - acc: 0.9934 - val_loss: 6.6341 - val_acc: 0.4310\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0230 - acc: 0.9945 - val_loss: 6.8306 - val_acc: 0.4136\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0292 - acc: 0.9930 - val_loss: 6.6898 - val_acc: 0.4191\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0284 - acc: 0.9939 - val_loss: 6.7349 - val_acc: 0.4219\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0289 - acc: 0.9939 - val_loss: 6.7274 - val_acc: 0.4253\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0204 - acc: 0.9951 - val_loss: 6.5323 - val_acc: 0.4250\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0235 - acc: 0.9943 - val_loss: 6.5207 - val_acc: 0.4353\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0308 - acc: 0.9935 - val_loss: 6.9463 - val_acc: 0.4182\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0321 - acc: 0.9933 - val_loss: 6.6384 - val_acc: 0.4284\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0214 - acc: 0.9951 - val_loss: 6.7282 - val_acc: 0.4275\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0232 - acc: 0.9949 - val_loss: 7.0202 - val_acc: 0.4205\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0299 - acc: 0.9942 - val_loss: 6.7664 - val_acc: 0.4284\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0284 - acc: 0.9939 - val_loss: 6.7457 - val_acc: 0.4245\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0326 - acc: 0.9931 - val_loss: 6.8690 - val_acc: 0.4240\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0246 - acc: 0.9940 - val_loss: 6.8737 - val_acc: 0.4259\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0360 - acc: 0.9927 - val_loss: 6.7527 - val_acc: 0.4307\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0279 - acc: 0.9938 - val_loss: 6.7974 - val_acc: 0.4266\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0200 - acc: 0.9950 - val_loss: 6.6801 - val_acc: 0.4329\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0232 - acc: 0.9947 - val_loss: 6.8958 - val_acc: 0.4215\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0316 - acc: 0.9930 - val_loss: 6.7506 - val_acc: 0.4277\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0235 - acc: 0.9950 - val_loss: 6.8714 - val_acc: 0.4263\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0245 - acc: 0.9944 - val_loss: 6.8297 - val_acc: 0.4313\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0324 - acc: 0.9931 - val_loss: 6.8163 - val_acc: 0.4263\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0333 - acc: 0.9930 - val_loss: 6.9398 - val_acc: 0.4285\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0260 - acc: 0.9944 - val_loss: 6.7865 - val_acc: 0.4229\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0262 - acc: 0.9944 - val_loss: 6.9639 - val_acc: 0.4280\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0308 - acc: 0.9938 - val_loss: 6.7958 - val_acc: 0.4262\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0224 - acc: 0.9951 - val_loss: 6.9685 - val_acc: 0.4211\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 31s 610us/step - loss: 0.0316 - acc: 0.9933 - val_loss: 6.8465 - val_acc: 0.4335\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0292 - acc: 0.9939 - val_loss: 7.1925 - val_acc: 0.4234\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0293 - acc: 0.9942 - val_loss: 6.9207 - val_acc: 0.4238\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0297 - acc: 0.9938 - val_loss: 6.9759 - val_acc: 0.4270\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0259 - acc: 0.9942 - val_loss: 6.9878 - val_acc: 0.4219\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0212 - acc: 0.9951 - val_loss: 6.9525 - val_acc: 0.4184\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0310 - acc: 0.9941 - val_loss: 7.1671 - val_acc: 0.4187\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0299 - acc: 0.9936 - val_loss: 7.2713 - val_acc: 0.4225\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0398 - acc: 0.9922 - val_loss: 6.8832 - val_acc: 0.4266\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0248 - acc: 0.9951 - val_loss: 7.1883 - val_acc: 0.4245\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0251 - acc: 0.9952 - val_loss: 7.0697 - val_acc: 0.4269\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0288 - acc: 0.9943 - val_loss: 7.1588 - val_acc: 0.4223\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0392 - acc: 0.9923 - val_loss: 7.0224 - val_acc: 0.4224\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0288 - acc: 0.9939 - val_loss: 7.1548 - val_acc: 0.4224\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 512)       295424    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 151,710,052\n",
      "Trainable params: 151,710,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0243 - acc: 0.9952 - val_loss: 7.3033 - val_acc: 0.4217\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0315 - acc: 0.9939 - val_loss: 7.1505 - val_acc: 0.4189\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0290 - acc: 0.9942 - val_loss: 7.0853 - val_acc: 0.4229\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0280 - acc: 0.9948 - val_loss: 7.1412 - val_acc: 0.4148\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0296 - acc: 0.9939 - val_loss: 7.2685 - val_acc: 0.4206\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0299 - acc: 0.9936 - val_loss: 7.0898 - val_acc: 0.4258\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0288 - acc: 0.9944 - val_loss: 7.1774 - val_acc: 0.4235\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0332 - acc: 0.9933 - val_loss: 7.3266 - val_acc: 0.4150\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0271 - acc: 0.9943 - val_loss: 7.2550 - val_acc: 0.4204\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0255 - acc: 0.9946 - val_loss: 7.2867 - val_acc: 0.4207\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0300 - acc: 0.9941 - val_loss: 7.2644 - val_acc: 0.4086\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0333 - acc: 0.9934 - val_loss: 7.2764 - val_acc: 0.4211\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0280 - acc: 0.9946 - val_loss: 7.2900 - val_acc: 0.4235\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0302 - acc: 0.9938 - val_loss: 7.2788 - val_acc: 0.4147\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0217 - acc: 0.9958 - val_loss: 7.3655 - val_acc: 0.4184\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0364 - acc: 0.9937 - val_loss: 7.4017 - val_acc: 0.4141\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0409 - acc: 0.9924 - val_loss: 7.4149 - val_acc: 0.4186\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0358 - acc: 0.9936 - val_loss: 7.5529 - val_acc: 0.4244\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0370 - acc: 0.9934 - val_loss: 7.4997 - val_acc: 0.4256\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0354 - acc: 0.9936 - val_loss: 7.3749 - val_acc: 0.4257\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0349 - acc: 0.9941 - val_loss: 7.4262 - val_acc: 0.4202\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0332 - acc: 0.9937 - val_loss: 7.5520 - val_acc: 0.4234\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0308 - acc: 0.9940 - val_loss: 7.4780 - val_acc: 0.4075\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0383 - acc: 0.9930 - val_loss: 7.5457 - val_acc: 0.4258\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0304 - acc: 0.9949 - val_loss: 7.6466 - val_acc: 0.4148\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0338 - acc: 0.9942 - val_loss: 7.7242 - val_acc: 0.4224\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0449 - acc: 0.9927 - val_loss: 7.7543 - val_acc: 0.4242\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0376 - acc: 0.9936 - val_loss: 7.6223 - val_acc: 0.4192\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0400 - acc: 0.9933 - val_loss: 7.6680 - val_acc: 0.4235\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0301 - acc: 0.9942 - val_loss: 7.7281 - val_acc: 0.4250\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0371 - acc: 0.9939 - val_loss: 7.7641 - val_acc: 0.4252\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0481 - acc: 0.9926 - val_loss: 7.6072 - val_acc: 0.4208\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0366 - acc: 0.9942 - val_loss: 7.8734 - val_acc: 0.4214\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.0382 - acc: 0.9939 - val_loss: 7.6692 - val_acc: 0.4235\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0414 - acc: 0.9939 - val_loss: 7.6521 - val_acc: 0.4210\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0445 - acc: 0.9929 - val_loss: 7.7495 - val_acc: 0.4228\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0488 - acc: 0.9924 - val_loss: 7.5588 - val_acc: 0.4236\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0307 - acc: 0.9947 - val_loss: 7.4860 - val_acc: 0.4227\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0418 - acc: 0.9936 - val_loss: 7.6049 - val_acc: 0.4287\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0375 - acc: 0.9936 - val_loss: 7.3985 - val_acc: 0.4207\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0305 - acc: 0.9944 - val_loss: 7.4473 - val_acc: 0.4291\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0412 - acc: 0.9931 - val_loss: 7.7274 - val_acc: 0.4245\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0403 - acc: 0.9935 - val_loss: 7.4654 - val_acc: 0.4257\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0349 - acc: 0.9944 - val_loss: 7.4479 - val_acc: 0.4233\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 603us/step - loss: 0.0339 - acc: 0.9938 - val_loss: 7.7024 - val_acc: 0.4209\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0401 - acc: 0.9934 - val_loss: 7.6480 - val_acc: 0.4308\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0359 - acc: 0.9939 - val_loss: 7.7025 - val_acc: 0.4291\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0435 - acc: 0.9930 - val_loss: 7.9015 - val_acc: 0.4194\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0435 - acc: 0.9934 - val_loss: 8.0196 - val_acc: 0.4262\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0449 - acc: 0.9935 - val_loss: 7.9775 - val_acc: 0.4196\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 84,305,764\n",
      "Trainable params: 84,305,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 0.0522 - acc: 0.9926 - val_loss: 7.9432 - val_acc: 0.4183\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0359 - acc: 0.9943 - val_loss: 8.0233 - val_acc: 0.4233\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0323 - acc: 0.9949 - val_loss: 8.0073 - val_acc: 0.4184\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0412 - acc: 0.9937 - val_loss: 8.0171 - val_acc: 0.4196\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0562 - acc: 0.9923 - val_loss: 7.9687 - val_acc: 0.4240\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0453 - acc: 0.9933 - val_loss: 7.8585 - val_acc: 0.4277\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0274 - acc: 0.9957 - val_loss: 7.9676 - val_acc: 0.4253\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0472 - acc: 0.9934 - val_loss: 8.0863 - val_acc: 0.4164\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0454 - acc: 0.9932 - val_loss: 7.8862 - val_acc: 0.4176\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0410 - acc: 0.9935 - val_loss: 8.0964 - val_acc: 0.4201\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0520 - acc: 0.9924 - val_loss: 7.9282 - val_acc: 0.4300\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0454 - acc: 0.9935 - val_loss: 7.8715 - val_acc: 0.4294\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0428 - acc: 0.9935 - val_loss: 8.0411 - val_acc: 0.4189\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0413 - acc: 0.9942 - val_loss: 8.0992 - val_acc: 0.4232\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0710 - acc: 0.9911 - val_loss: 7.9704 - val_acc: 0.4223\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0481 - acc: 0.9936 - val_loss: 7.9469 - val_acc: 0.4290\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0369 - acc: 0.9950 - val_loss: 7.8722 - val_acc: 0.4280\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0474 - acc: 0.9937 - val_loss: 7.9585 - val_acc: 0.4227\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0478 - acc: 0.9929 - val_loss: 8.0118 - val_acc: 0.4247\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 0.0559 - acc: 0.9927 - val_loss: 8.0317 - val_acc: 0.4221\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0595 - acc: 0.9922 - val_loss: 8.0500 - val_acc: 0.4253\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0430 - acc: 0.9939 - val_loss: 8.2090 - val_acc: 0.4222\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0547 - acc: 0.9928 - val_loss: 8.1812 - val_acc: 0.4252\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0441 - acc: 0.9939 - val_loss: 8.0455 - val_acc: 0.4251\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0639 - acc: 0.9915 - val_loss: 8.3555 - val_acc: 0.4172\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0442 - acc: 0.9942 - val_loss: 8.1505 - val_acc: 0.4224\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0636 - acc: 0.9919 - val_loss: 8.1170 - val_acc: 0.4232\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0568 - acc: 0.9925 - val_loss: 8.1297 - val_acc: 0.4333\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0484 - acc: 0.9938 - val_loss: 8.2646 - val_acc: 0.4195\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0588 - acc: 0.9924 - val_loss: 8.4204 - val_acc: 0.4193\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0546 - acc: 0.9931 - val_loss: 8.3560 - val_acc: 0.4278\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0552 - acc: 0.9932 - val_loss: 8.3510 - val_acc: 0.4237\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0696 - acc: 0.9920 - val_loss: 8.5378 - val_acc: 0.4228\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0563 - acc: 0.9936 - val_loss: 8.5688 - val_acc: 0.4193\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0924 - acc: 0.9902 - val_loss: 8.5696 - val_acc: 0.4190\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 0.0835 - acc: 0.9913 - val_loss: 8.7478 - val_acc: 0.4157\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.0672 - acc: 0.9930 - val_loss: 8.6387 - val_acc: 0.4214\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0802 - acc: 0.9920 - val_loss: 8.7322 - val_acc: 0.4178\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.0858 - acc: 0.9908 - val_loss: 8.6997 - val_acc: 0.4157\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.0837 - acc: 0.9911 - val_loss: 8.6991 - val_acc: 0.4198\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 30s 605us/step - loss: 0.0700 - acc: 0.9926 - val_loss: 8.6377 - val_acc: 0.4246\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 30s 604us/step - loss: 0.0793 - acc: 0.9924 - val_loss: 8.7017 - val_acc: 0.4234\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 608us/step - loss: 0.1077 - acc: 0.9900 - val_loss: 8.8152 - val_acc: 0.4156\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 30s 610us/step - loss: 0.1187 - acc: 0.9890 - val_loss: 8.6455 - val_acc: 0.4309\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.0891 - acc: 0.9915 - val_loss: 8.6893 - val_acc: 0.4283\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.1033 - acc: 0.9905 - val_loss: 8.8450 - val_acc: 0.4165\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.1136 - acc: 0.9894 - val_loss: 8.7795 - val_acc: 0.4213\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 609us/step - loss: 0.1343 - acc: 0.9884 - val_loss: 8.8928 - val_acc: 0.4184\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 606us/step - loss: 0.1229 - acc: 0.9892 - val_loss: 8.9119 - val_acc: 0.4193\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 0.1387 - acc: 0.9883 - val_loss: 8.9658 - val_acc: 0.4188\n"
     ]
    }
   ],
   "source": [
    "# For cifar100\n",
    "cifar100_accu = 0.4042\n",
    "layers = 7\n",
    "params_count_layer100, min_val_loss_layer100, min_val_acc100 = modified_cn_vggA(X_train100, y_train100, X_val100, y_val100, layers, ini_filter=64, \n",
    "                                              input_shape=(32, 32, 3), classes=100, epoch=50, batch_size=64, \n",
    "                                              early_stop=False, verbose=1, compa=cifar100_accu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r\"cn_cifar100\" + \".txt\", np.asmatrix([params_count_layer100, min_val_loss_layer100, min_val_acc100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_count_layer10, min_val_loss_layer10 = np.loadtxt(\"cn_cifar10.txt\")\n",
    "params_count_layer100, min_val_loss_layer100, min_val_acc100 = np.loadtxt('cn_cifar100.txt')\n",
    "\n",
    "layers = 7\n",
    "layer_range = range(layers, 0, -1)\n",
    "cifar100_bar = np.copy(layer_range)\n",
    "cifar100_bar[:] = 40.42\n",
    "\n",
    "plt.plot(layer_range, min_val_loss_layer10, \"r-+\", linewidth=2)\n",
    "plt.plot(layer_range, min_val_loss_layer100, \"b-*\", linewidth=2)\n",
    "plt.legend(['cifar10', 'cifar100'])\n",
    "plt.xlabel('# of Convolutional Layers')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.xlim([layer_range[0], layer_range[-1]])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(layer_range, cifar100_bar, \"g\", linewidth=0.5)\n",
    "plt.plot(layer_range, min_val_acc100*100, \"b-*\", linewidth=2)\n",
    "plt.xlabel('# of Convolutional Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Original Accuracy'])\n",
    "plt.xlim([layer_range[0], layer_range[-1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### By removing top 3 convolutional layers toward the input, our accuracy is improved by ~3% on cifar-100 data, proving that the full model was overfitting. However, it is a better idea to remove filters toward output at the fully-connected layers (FCN) because convolutional layers are for extracting the meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine how many fcn filters we can remove until accuracy drops by 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify layers toward the output (dense layer)\n",
    "def modified_fcn_vggA(X_train, y_train, X_val, y_val, compa, decrement=500, input_shape=(32, 32, 3), \n",
    "                  classes=10, epoch=5, batch_size=64, early_stop=True, verbose=1, lr=0.0001, ini_filter=64):\n",
    "    \n",
    "    params_count, min_val_loss, min_val_acc = [], [], []\n",
    "    for i in range(4096-500, 596, -decrement):  # Number of layers is decremented to see at which # of layers, accuracy will drop by 2%\n",
    "        clear_session()\n",
    "        \n",
    "        if early_stop:\n",
    "            es = EarlyStopping(restore_best_weights=True)\n",
    "            \n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter, (3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*2, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*4, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*4, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.Conv2D(ini_filter*8, (3,3), padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(i, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(i, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=tf.train.AdamOptimizer(lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        # Count param\n",
    "        params_count.append(i)\n",
    "        \n",
    "        if early_stop:\n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  callbacks=[es],\n",
    "                  validation_data=(X_val, y_val))\n",
    "        else: \n",
    "            hist = model.fit(X_train, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=epoch,\n",
    "                  verbose=verbose,\n",
    "                  validation_data=(X_val, y_val))\n",
    "        \n",
    "        # Compare accuracy with full model to check if it drops below 2%\n",
    "        if compa-hist.history['val_acc'][-1]>0.02:\n",
    "            print('At ' + str(i) + ' filters in fcn layers, accuracy starts to drop by more than 2%')\n",
    "        \n",
    "        curr_l = hist.history['val_loss']\n",
    "        min_val_loss.append(curr_l[-1])\n",
    "        min_val_acc.append(hist.history['val_acc'][-1])\n",
    "    return params_count, min_val_loss, min_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3596)              1844748   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3596)              12934812  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                35970     \n",
      "=================================================================\n",
      "Total params: 24,036,010\n",
      "Trainable params: 24,036,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0798 - acc: 0.9730 - val_loss: 1.3016 - val_acc: 0.7402\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0779 - acc: 0.9731 - val_loss: 1.3806 - val_acc: 0.7327\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0724 - acc: 0.9754 - val_loss: 1.2264 - val_acc: 0.7385\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0646 - acc: 0.9787 - val_loss: 1.3409 - val_acc: 0.7404\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0649 - acc: 0.9784 - val_loss: 1.2807 - val_acc: 0.7450\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0563 - acc: 0.9811 - val_loss: 1.2663 - val_acc: 0.7368\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0577 - acc: 0.9800 - val_loss: 1.3820 - val_acc: 0.7354\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0538 - acc: 0.9819 - val_loss: 1.3479 - val_acc: 0.7374\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0542 - acc: 0.9824 - val_loss: 1.4061 - val_acc: 0.7447\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0449 - acc: 0.9849 - val_loss: 1.3489 - val_acc: 0.7395\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0531 - acc: 0.9827 - val_loss: 1.4546 - val_acc: 0.7373\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0445 - acc: 0.9854 - val_loss: 1.4861 - val_acc: 0.7301\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0447 - acc: 0.9850 - val_loss: 1.3632 - val_acc: 0.7546\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0428 - acc: 0.9853 - val_loss: 1.5703 - val_acc: 0.7369\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0433 - acc: 0.9862 - val_loss: 1.5187 - val_acc: 0.7426\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0417 - acc: 0.9865 - val_loss: 1.4438 - val_acc: 0.7413\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0404 - acc: 0.9868 - val_loss: 1.3212 - val_acc: 0.7417\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0376 - acc: 0.9879 - val_loss: 1.3886 - val_acc: 0.7417\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0377 - acc: 0.9874 - val_loss: 1.3458 - val_acc: 0.7491\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0391 - acc: 0.9874 - val_loss: 1.4737 - val_acc: 0.7399\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0352 - acc: 0.9883 - val_loss: 1.5084 - val_acc: 0.7450\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0332 - acc: 0.9891 - val_loss: 1.5552 - val_acc: 0.7512\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0379 - acc: 0.9880 - val_loss: 1.5653 - val_acc: 0.7415\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0314 - acc: 0.9896 - val_loss: 1.3634 - val_acc: 0.7563\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0339 - acc: 0.9892 - val_loss: 1.3920 - val_acc: 0.7582\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0328 - acc: 0.9897 - val_loss: 1.5717 - val_acc: 0.7434\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0287 - acc: 0.9908 - val_loss: 1.6174 - val_acc: 0.7446\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0286 - acc: 0.9906 - val_loss: 1.6027 - val_acc: 0.7463\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0330 - acc: 0.9896 - val_loss: 1.4203 - val_acc: 0.7443\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0286 - acc: 0.9911 - val_loss: 1.4144 - val_acc: 0.7468\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0295 - acc: 0.9910 - val_loss: 1.5757 - val_acc: 0.7469\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0267 - acc: 0.9914 - val_loss: 1.6034 - val_acc: 0.7324\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0298 - acc: 0.9905 - val_loss: 1.5721 - val_acc: 0.7460\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 1.4529 - val_acc: 0.7539\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 1.5216 - val_acc: 0.7394\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 1.4761 - val_acc: 0.7593\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0282 - acc: 0.9914 - val_loss: 1.6020 - val_acc: 0.7400\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0252 - acc: 0.9922 - val_loss: 1.6279 - val_acc: 0.7458\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0315 - acc: 0.9910 - val_loss: 1.3945 - val_acc: 0.7540\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0222 - acc: 0.9931 - val_loss: 1.5889 - val_acc: 0.7496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0265 - acc: 0.9922 - val_loss: 1.3555 - val_acc: 0.7440\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0273 - acc: 0.9920 - val_loss: 1.6376 - val_acc: 0.7509\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0209 - acc: 0.9937 - val_loss: 1.5991 - val_acc: 0.7566\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0255 - acc: 0.9920 - val_loss: 1.4731 - val_acc: 0.7542\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 1.7080 - val_acc: 0.7560\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 1.5873 - val_acc: 0.7596\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0264 - acc: 0.9924 - val_loss: 1.5953 - val_acc: 0.7512\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 1.5968 - val_acc: 0.7563\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0253 - acc: 0.9923 - val_loss: 1.5666 - val_acc: 0.7641\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 1.7372 - val_acc: 0.7518\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3096)              1588248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3096)              9588312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                30970     \n",
      "=================================================================\n",
      "Total params: 20,428,010\n",
      "Trainable params: 20,428,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0232 - acc: 0.9930 - val_loss: 1.7593 - val_acc: 0.7430\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0208 - acc: 0.9941 - val_loss: 1.4604 - val_acc: 0.7658\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0190 - acc: 0.9941 - val_loss: 1.7405 - val_acc: 0.7601\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0206 - acc: 0.9935 - val_loss: 1.8610 - val_acc: 0.7570\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0203 - acc: 0.9938 - val_loss: 1.5470 - val_acc: 0.7561\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 1.6523 - val_acc: 0.7486\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 1.6949 - val_acc: 0.7470\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0176 - acc: 0.9952 - val_loss: 1.4971 - val_acc: 0.7575\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0177 - acc: 0.9945 - val_loss: 1.5943 - val_acc: 0.7599\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0176 - acc: 0.9945 - val_loss: 1.7305 - val_acc: 0.7583\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0207 - acc: 0.9934 - val_loss: 1.7527 - val_acc: 0.7609\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0243 - acc: 0.9930 - val_loss: 1.3886 - val_acc: 0.7591\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0166 - acc: 0.9945 - val_loss: 1.6807 - val_acc: 0.7584\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0193 - acc: 0.9942 - val_loss: 1.7940 - val_acc: 0.7593\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0172 - acc: 0.9947 - val_loss: 1.4868 - val_acc: 0.7511\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 1.6689 - val_acc: 0.7638\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 1.7693 - val_acc: 0.7680\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0225 - acc: 0.9933 - val_loss: 1.5622 - val_acc: 0.7667\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0128 - acc: 0.9962 - val_loss: 1.8887 - val_acc: 0.7578\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0204 - acc: 0.9941 - val_loss: 1.6276 - val_acc: 0.7604\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 1.6191 - val_acc: 0.7586\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 1.9128 - val_acc: 0.7638\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0247 - acc: 0.9932 - val_loss: 1.5810 - val_acc: 0.7502\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0178 - acc: 0.9948 - val_loss: 1.6300 - val_acc: 0.7674\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 1.7613 - val_acc: 0.7568\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0162 - acc: 0.9950 - val_loss: 1.9762 - val_acc: 0.7627\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0181 - acc: 0.9949 - val_loss: 1.9322 - val_acc: 0.7576\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0174 - acc: 0.9948 - val_loss: 1.5359 - val_acc: 0.7649\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0172 - acc: 0.9951 - val_loss: 1.6142 - val_acc: 0.7620\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0159 - acc: 0.9958 - val_loss: 1.8628 - val_acc: 0.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0149 - acc: 0.9960 - val_loss: 1.6537 - val_acc: 0.7672\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0165 - acc: 0.9957 - val_loss: 1.4710 - val_acc: 0.7620\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0163 - acc: 0.9955 - val_loss: 1.7367 - val_acc: 0.7518\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0143 - acc: 0.9961 - val_loss: 1.6538 - val_acc: 0.7678\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0155 - acc: 0.9957 - val_loss: 1.7360 - val_acc: 0.7580\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0118 - acc: 0.9965 - val_loss: 1.5516 - val_acc: 0.7603\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 1.6792 - val_acc: 0.7689\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0105 - acc: 0.9969 - val_loss: 1.7733 - val_acc: 0.7574\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0168 - acc: 0.9953 - val_loss: 1.5992 - val_acc: 0.7684\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0140 - acc: 0.9961 - val_loss: 1.5770 - val_acc: 0.7662\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0122 - acc: 0.9962 - val_loss: 1.8481 - val_acc: 0.7579\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0164 - acc: 0.9954 - val_loss: 1.5171 - val_acc: 0.7675\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 1.3393 - val_acc: 0.7553\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0149 - acc: 0.9956 - val_loss: 1.6904 - val_acc: 0.7572\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0160 - acc: 0.9956 - val_loss: 1.7083 - val_acc: 0.7626\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0111 - acc: 0.9968 - val_loss: 1.7429 - val_acc: 0.7729\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0149 - acc: 0.9954 - val_loss: 1.6790 - val_acc: 0.7578\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0117 - acc: 0.9965 - val_loss: 1.6306 - val_acc: 0.7572\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0158 - acc: 0.9957 - val_loss: 1.6088 - val_acc: 0.7573\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 1.8343 - val_acc: 0.7631\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2596)              1331748   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2596)              6741812   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                25970     \n",
      "=================================================================\n",
      "Total params: 17,320,010\n",
      "Trainable params: 17,320,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0189 - acc: 0.9945 - val_loss: 1.6344 - val_acc: 0.7678\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0139 - acc: 0.9963 - val_loss: 1.6565 - val_acc: 0.7728\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.0114 - acc: 0.9969 - val_loss: 1.8770 - val_acc: 0.7623\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 25s 499us/step - loss: 0.0112 - acc: 0.9969 - val_loss: 1.8141 - val_acc: 0.7644\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0129 - acc: 0.9961 - val_loss: 1.7404 - val_acc: 0.7649\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0178 - acc: 0.9956 - val_loss: 1.5368 - val_acc: 0.7513\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0150 - acc: 0.9959 - val_loss: 1.7511 - val_acc: 0.7687\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0143 - acc: 0.9961 - val_loss: 1.6990 - val_acc: 0.7604\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 42s 849us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 1.6509 - val_acc: 0.7648\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 27s 531us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 1.8529 - val_acc: 0.7427\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 27s 532us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 1.5404 - val_acc: 0.7600\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 0.0124 - acc: 0.9964 - val_loss: 1.8185 - val_acc: 0.7725\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0141 - acc: 0.9965 - val_loss: 1.7761 - val_acc: 0.7686\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 1.7093 - val_acc: 0.7642\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 1.7482 - val_acc: 0.7702\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0085 - acc: 0.9977 - val_loss: 1.8704 - val_acc: 0.7610\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0146 - acc: 0.9956 - val_loss: 1.7582 - val_acc: 0.7673\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0157 - acc: 0.9960 - val_loss: 1.5697 - val_acc: 0.7670\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 0.0142 - acc: 0.9961 - val_loss: 1.7471 - val_acc: 0.7627\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 1.7861 - val_acc: 0.7639\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 26s 523us/step - loss: 0.0220 - acc: 0.9945 - val_loss: 1.7111 - val_acc: 0.7545\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 0.0098 - acc: 0.9972 - val_loss: 1.6010 - val_acc: 0.7706\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 1.9943 - val_acc: 0.7596\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0166 - acc: 0.9952 - val_loss: 1.6876 - val_acc: 0.7612\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0122 - acc: 0.9966 - val_loss: 1.5766 - val_acc: 0.7698\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0129 - acc: 0.9963 - val_loss: 1.7165 - val_acc: 0.7696\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 26s 520us/step - loss: 0.0087 - acc: 0.9974 - val_loss: 1.8380 - val_acc: 0.7694\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 27s 531us/step - loss: 0.0128 - acc: 0.9968 - val_loss: 2.0972 - val_acc: 0.7621\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 26s 517us/step - loss: 0.0180 - acc: 0.9956 - val_loss: 1.7480 - val_acc: 0.7714\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.0112 - acc: 0.9971 - val_loss: 1.6681 - val_acc: 0.7720\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 1.7102 - val_acc: 0.7687\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 0.0118 - acc: 0.9967 - val_loss: 1.6451 - val_acc: 0.7638 - loss: 0.0119 - acc: 0.\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 0.0106 - acc: 0.9971 - val_loss: 1.7780 - val_acc: 0.7666\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 27s 532us/step - loss: 0.0108 - acc: 0.9968 - val_loss: 1.6815 - val_acc: 0.7703\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.0125 - acc: 0.9963 - val_loss: 1.7428 - val_acc: 0.7705\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0122 - acc: 0.9968 - val_loss: 1.7227 - val_acc: 0.7562\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0113 - acc: 0.9970 - val_loss: 1.7646 - val_acc: 0.7663\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 1.6199 - val_acc: 0.7713\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0118 - acc: 0.9968 - val_loss: 1.8048 - val_acc: 0.7622\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 1.6851 - val_acc: 0.7682\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 1.7878 - val_acc: 0.7681\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 26s 520us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 1.8109 - val_acc: 0.7697\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 0.0167 - acc: 0.9956 - val_loss: 1.7150 - val_acc: 0.7660\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 25s 490us/step - loss: 0.0090 - acc: 0.9980 - val_loss: 1.8557 - val_acc: 0.7760\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0142 - acc: 0.9967 - val_loss: 1.8071 - val_acc: 0.7519\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 1.5354 - val_acc: 0.7708\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0086 - acc: 0.9980 - val_loss: 1.7925 - val_acc: 0.7642\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0133 - acc: 0.9969 - val_loss: 1.6193 - val_acc: 0.7673\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 1.9344 - val_acc: 0.7639\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0147 - acc: 0.9961 - val_loss: 1.6936 - val_acc: 0.7747\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2096)              1075248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2096)              4395312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20970     \n",
      "=================================================================\n",
      "Total params: 14,712,010\n",
      "Trainable params: 14,712,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 1.7205 - val_acc: 0.7712\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0100 - acc: 0.9974 - val_loss: 1.7516 - val_acc: 0.7611\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0100 - acc: 0.9974 - val_loss: 1.7044 - val_acc: 0.7673\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 1.5675 - val_acc: 0.7741\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0144 - acc: 0.9965 - val_loss: 1.5897 - val_acc: 0.7491\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 1.8808 - val_acc: 0.7595\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0112 - acc: 0.9970 - val_loss: 1.7042 - val_acc: 0.7744\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 1.8543 - val_acc: 0.7712\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0099 - acc: 0.9978 - val_loss: 1.7550 - val_acc: 0.7635\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 2.0431 - val_acc: 0.7680\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0085 - acc: 0.9977 - val_loss: 1.8484 - val_acc: 0.7683\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 2.0127 - val_acc: 0.7755\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 1.5276 - val_acc: 0.7681\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 1.8725 - val_acc: 0.7604\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0093 - acc: 0.9972 - val_loss: 1.9119 - val_acc: 0.7704\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 1.8423 - val_acc: 0.7709\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0135 - acc: 0.9967 - val_loss: 1.6375 - val_acc: 0.7613\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0119 - acc: 0.9974 - val_loss: 1.7239 - val_acc: 0.7702\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0148 - acc: 0.9961 - val_loss: 1.6177 - val_acc: 0.7657\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0076 - acc: 0.9980 - val_loss: 1.7334 - val_acc: 0.7614\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0048 - acc: 0.9986 - val_loss: 2.0003 - val_acc: 0.7672\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 2.1053 - val_acc: 0.7653\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 1.5334 - val_acc: 0.7588\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0094 - acc: 0.9975 - val_loss: 1.7193 - val_acc: 0.7703\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 2.0603 - val_acc: 0.7738\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0181 - acc: 0.9954 - val_loss: 1.7384 - val_acc: 0.7668\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0099 - acc: 0.9974 - val_loss: 1.8243 - val_acc: 0.7750\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0108 - acc: 0.9973 - val_loss: 1.6729 - val_acc: 0.7604\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0087 - acc: 0.9977 - val_loss: 1.7957 - val_acc: 0.7735\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0118 - acc: 0.9973 - val_loss: 1.8749 - val_acc: 0.7696\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 2.0086 - val_acc: 0.7664\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0123 - acc: 0.9970 - val_loss: 1.7519 - val_acc: 0.7723\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 1.7358 - val_acc: 0.7739\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0097 - acc: 0.9975 - val_loss: 1.6251 - val_acc: 0.7634\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 1.8318 - val_acc: 0.7752\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0115 - acc: 0.9975 - val_loss: 1.6840 - val_acc: 0.7670\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 1.6736 - val_acc: 0.7679\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 1.7930 - val_acc: 0.7628\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0145 - acc: 0.9965 - val_loss: 1.3789 - val_acc: 0.7624\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0091 - acc: 0.9977 - val_loss: 1.8303 - val_acc: 0.7715\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 2.0391 - val_acc: 0.7694\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0084 - acc: 0.9979 - val_loss: 2.0130 - val_acc: 0.7698\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0134 - acc: 0.9966 - val_loss: 1.7423 - val_acc: 0.7575\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0116 - acc: 0.9971 - val_loss: 1.8042 - val_acc: 0.7678\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0101 - acc: 0.9973 - val_loss: 1.9020 - val_acc: 0.7719\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 1.9950 - val_acc: 0.7654\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 1.8701 - val_acc: 0.7744\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0112 - acc: 0.9973 - val_loss: 1.6505 - val_acc: 0.7680\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0107 - acc: 0.9974 - val_loss: 1.8107 - val_acc: 0.7769\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 1.7465 - val_acc: 0.7682\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1596)              818748    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1596)              2548812   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                15970     \n",
      "=================================================================\n",
      "Total params: 12,604,010\n",
      "Trainable params: 12,604,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 1.8313 - val_acc: 0.7664\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0152 - acc: 0.9963 - val_loss: 1.7932 - val_acc: 0.7727\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0079 - acc: 0.9980 - val_loss: 1.7672 - val_acc: 0.7678\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0077 - acc: 0.9980 - val_loss: 1.9605 - val_acc: 0.7682\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 2.0166 - val_acc: 0.7721\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0081 - acc: 0.9978 - val_loss: 1.8716 - val_acc: 0.7754\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 1.6968 - val_acc: 0.7677\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0142 - acc: 0.9965 - val_loss: 1.7174 - val_acc: 0.7746\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0086 - acc: 0.9979 - val_loss: 1.5912 - val_acc: 0.7647\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 1.6296 - val_acc: 0.7665\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 1.8717 - val_acc: 0.7773\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0072 - acc: 0.9981 - val_loss: 1.8326 - val_acc: 0.7598\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0137 - acc: 0.9967 - val_loss: 1.9300 - val_acc: 0.7778\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0043 - acc: 0.9989 - val_loss: 2.0711 - val_acc: 0.7795\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0113 - acc: 0.9972 - val_loss: 1.9991 - val_acc: 0.7732\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0145 - acc: 0.9962 - val_loss: 1.7580 - val_acc: 0.7730\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0092 - acc: 0.9977 - val_loss: 1.6006 - val_acc: 0.7776\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0097 - acc: 0.9976 - val_loss: 1.4979 - val_acc: 0.7783\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 1.9438 - val_acc: 0.7764\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0139 - acc: 0.9961 - val_loss: 1.6555 - val_acc: 0.7800\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0068 - acc: 0.9983 - val_loss: 2.0175 - val_acc: 0.7718\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0134 - acc: 0.9972 - val_loss: 1.7577 - val_acc: 0.7689\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 1.9643 - val_acc: 0.7756\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0122 - acc: 0.9971 - val_loss: 1.8964 - val_acc: 0.7741\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0116 - acc: 0.9974 - val_loss: 1.7572 - val_acc: 0.7714\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0078 - acc: 0.9980 - val_loss: 1.6754 - val_acc: 0.7741\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0057 - acc: 0.9986 - val_loss: 1.8636 - val_acc: 0.7749\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0102 - acc: 0.9970 - val_loss: 1.8031 - val_acc: 0.7751\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0088 - acc: 0.9978 - val_loss: 1.9621 - val_acc: 0.7781\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0135 - acc: 0.9972 - val_loss: 1.7365 - val_acc: 0.7720\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0083 - acc: 0.9979 - val_loss: 1.7475 - val_acc: 0.7727\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 1.8355 - val_acc: 0.7738\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 1.6898 - val_acc: 0.7666\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 24s 470us/step - loss: 0.0091 - acc: 0.9976 - val_loss: 1.7903 - val_acc: 0.7757\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 1.8819 - val_acc: 0.7731\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0084 - acc: 0.9981 - val_loss: 1.8629 - val_acc: 0.7760\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 1.8270 - val_acc: 0.7641\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 1.7836 - val_acc: 0.7708\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0088 - acc: 0.9980 - val_loss: 1.8763 - val_acc: 0.7692\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0101 - acc: 0.9976 - val_loss: 1.9734 - val_acc: 0.7804\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0073 - acc: 0.9985 - val_loss: 2.0087 - val_acc: 0.7699\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0103 - acc: 0.9969 - val_loss: 1.9995 - val_acc: 0.7568\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0105 - acc: 0.9972 - val_loss: 1.7328 - val_acc: 0.7769\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0093 - acc: 0.9978 - val_loss: 1.6955 - val_acc: 0.7676\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0134 - acc: 0.9971 - val_loss: 1.8168 - val_acc: 0.7768\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0089 - acc: 0.9977 - val_loss: 1.9523 - val_acc: 0.7576\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0076 - acc: 0.9982 - val_loss: 1.8719 - val_acc: 0.7788\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0117 - acc: 0.9977 - val_loss: 1.6191 - val_acc: 0.7616\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0106 - acc: 0.9976 - val_loss: 1.7400 - val_acc: 0.7795\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0105 - acc: 0.9974 - val_loss: 1.8308 - val_acc: 0.7616\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1096)              562248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1096)              1202312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10970     \n",
      "=================================================================\n",
      "Total params: 10,996,010\n",
      "Trainable params: 10,996,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0117 - acc: 0.9971 - val_loss: 1.6333 - val_acc: 0.7653\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 1.8811 - val_acc: 0.7726\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0090 - acc: 0.9977 - val_loss: 1.6374 - val_acc: 0.7682\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0091 - acc: 0.9976 - val_loss: 1.7714 - val_acc: 0.7725\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0076 - acc: 0.9981 - val_loss: 1.7321 - val_acc: 0.7760\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 1.8639 - val_acc: 0.7753\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 22s 444us/step - loss: 0.0089 - acc: 0.9978 - val_loss: 1.8078 - val_acc: 0.7706\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 2.0520 - val_acc: 0.7804\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0050 - acc: 0.9989 - val_loss: 1.8147 - val_acc: 0.7642\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0160 - acc: 0.9964 - val_loss: 1.5910 - val_acc: 0.7747\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 1.9018 - val_acc: 0.7747\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0104 - acc: 0.9977 - val_loss: 1.5095 - val_acc: 0.7598\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 2.0025 - val_acc: 0.7729\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.0120 - acc: 0.9973 - val_loss: 1.7863 - val_acc: 0.7564\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0091 - acc: 0.9978 - val_loss: 1.7384 - val_acc: 0.7793\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 4.9140e-04 - acc: 0.9999 - val_loss: 2.0480 - val_acc: 0.7784\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0100 - acc: 0.9977 - val_loss: 1.8683 - val_acc: 0.7723\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 1.9733 - val_acc: 0.7753\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.0063 - acc: 0.9982 - val_loss: 1.7861 - val_acc: 0.7652\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 2.0231 - val_acc: 0.7730\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0141 - acc: 0.9965 - val_loss: 1.7861 - val_acc: 0.7693\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0077 - acc: 0.9984 - val_loss: 2.0251 - val_acc: 0.7704\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 2.1019 - val_acc: 0.7774\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0094 - acc: 0.9975 - val_loss: 2.1936 - val_acc: 0.7655\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.0115 - acc: 0.9973 - val_loss: 1.8356 - val_acc: 0.7781\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 1.7604 - val_acc: 0.7732\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 2.1278 - val_acc: 0.7645\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0131 - acc: 0.9968 - val_loss: 2.0730 - val_acc: 0.7653\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0096 - acc: 0.9976 - val_loss: 1.7802 - val_acc: 0.7733\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0099 - acc: 0.9975 - val_loss: 1.8497 - val_acc: 0.7700\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 25s 504us/step - loss: 0.0085 - acc: 0.9981 - val_loss: 2.0193 - val_acc: 0.7799\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 0.0113 - acc: 0.9976 - val_loss: 1.8266 - val_acc: 0.7741\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.0036 - acc: 0.9992 - val_loss: 2.2003 - val_acc: 0.7720\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.0079 - acc: 0.9980 - val_loss: 1.8608 - val_acc: 0.7656\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.0071 - acc: 0.9982 - val_loss: 1.8218 - val_acc: 0.7720\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 2.0062 - val_acc: 0.7707\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 26s 530us/step - loss: 0.0113 - acc: 0.9975 - val_loss: 1.7562 - val_acc: 0.7669\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.0147 - acc: 0.9966 - val_loss: 1.8631 - val_acc: 0.7736\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0044 - acc: 0.9992 - val_loss: 1.6958 - val_acc: 0.7689\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.0156 - acc: 0.9973 - val_loss: 1.6409 - val_acc: 0.7556\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 0.0068 - acc: 0.9982 - val_loss: 1.8754 - val_acc: 0.7710\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 2.2873 - val_acc: 0.7752\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.0185 - acc: 0.9962 - val_loss: 1.6416 - val_acc: 0.7723\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 0.0115 - acc: 0.9974 - val_loss: 1.7836 - val_acc: 0.7767\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0073 - acc: 0.9985 - val_loss: 1.8411 - val_acc: 0.7728\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.0084 - acc: 0.9981 - val_loss: 1.5632 - val_acc: 0.7619\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 1.8066 - val_acc: 0.7802\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 1.7561 - val_acc: 0.7761\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 26s 513us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 2.0464 - val_acc: 0.7819\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.0085 - acc: 0.9978 - val_loss: 1.7917 - val_acc: 0.7723\n"
     ]
    }
   ],
   "source": [
    "# The # of filters is decremented from 4096 to 1096, with input 'decrement' as the step size\n",
    "cifar10_accu = 0.752\n",
    "decrement = 500\n",
    "params_count_layer10, min_val_loss_layer10, min_val_acc10 = modified_fcn_vggA(X_train10, y_train10, X_val10, y_val10, \n",
    "                                                                              decrement=decrement, \n",
    "                                              input_shape=(32, 32, 3), classes=10, epoch=50, batch_size=64, \n",
    "                                              early_stop=False, verbose=1, compa=cifar10_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results so we don't have to re-train\n",
    "np.savetxt(r\"fcn_cifar10\" + \".txt\", np.asmatrix([params_count_layer10, min_val_loss_layer10, min_val_acc10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3596)              1844748   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3596)              12934812  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               359700    \n",
      "=================================================================\n",
      "Total params: 24,359,740\n",
      "Trainable params: 24,359,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 27s 547us/step - loss: 3.9024 - acc: 0.0949 - val_loss: 3.4332 - val_acc: 0.1671\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 3.1734 - acc: 0.2183 - val_loss: 2.9843 - val_acc: 0.2647\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 2.7170 - acc: 0.3062 - val_loss: 2.7128 - val_acc: 0.3158\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 2.3397 - acc: 0.3824 - val_loss: 2.5781 - val_acc: 0.3431\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 1.9707 - acc: 0.4650 - val_loss: 2.4201 - val_acc: 0.3871\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.5845 - acc: 0.5530 - val_loss: 2.5246 - val_acc: 0.3894\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.1793 - acc: 0.6501 - val_loss: 2.6043 - val_acc: 0.3993\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.8218 - acc: 0.7475 - val_loss: 2.9248 - val_acc: 0.3975\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.5827 - acc: 0.8163 - val_loss: 3.2135 - val_acc: 0.3924\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.4199 - acc: 0.8641 - val_loss: 3.7361 - val_acc: 0.3792\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.3240 - acc: 0.8943 - val_loss: 3.6726 - val_acc: 0.3895\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.2784 - acc: 0.9103 - val_loss: 4.0645 - val_acc: 0.3856\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.2357 - acc: 0.9244 - val_loss: 4.1274 - val_acc: 0.3936\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.2131 - acc: 0.9316 - val_loss: 4.2858 - val_acc: 0.3928\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.1941 - acc: 0.9381 - val_loss: 4.3848 - val_acc: 0.3907\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.1839 - acc: 0.9420 - val_loss: 4.3930 - val_acc: 0.3708\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.1627 - acc: 0.9482 - val_loss: 4.4423 - val_acc: 0.3904\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.1661 - acc: 0.9482 - val_loss: 4.3244 - val_acc: 0.3937\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.1580 - acc: 0.9522 - val_loss: 4.4976 - val_acc: 0.3796\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.1467 - acc: 0.9549 - val_loss: 4.4455 - val_acc: 0.3806\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.1380 - acc: 0.9561 - val_loss: 4.5780 - val_acc: 0.3871\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.1337 - acc: 0.9584 - val_loss: 4.6496 - val_acc: 0.3859\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.1312 - acc: 0.9605 - val_loss: 4.4393 - val_acc: 0.3890\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.1290 - acc: 0.9591 - val_loss: 4.6178 - val_acc: 0.3962\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.1229 - acc: 0.9615 - val_loss: 4.5431 - val_acc: 0.3890\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.1170 - acc: 0.9631 - val_loss: 4.6139 - val_acc: 0.4001\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.1110 - acc: 0.9659 - val_loss: 4.5735 - val_acc: 0.3951\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.1119 - acc: 0.9657 - val_loss: 4.2981 - val_acc: 0.3887\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.1010 - acc: 0.9691 - val_loss: 4.4502 - val_acc: 0.3912\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.1026 - acc: 0.9692 - val_loss: 4.5720 - val_acc: 0.3839\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.1107 - acc: 0.9653 - val_loss: 4.7135 - val_acc: 0.3910\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.1002 - acc: 0.9688 - val_loss: 4.6186 - val_acc: 0.3910\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0959 - acc: 0.9705 - val_loss: 4.5034 - val_acc: 0.3889\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0894 - acc: 0.9725 - val_loss: 4.6034 - val_acc: 0.3880\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0902 - acc: 0.9729 - val_loss: 4.6805 - val_acc: 0.3910\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0971 - acc: 0.9708 - val_loss: 4.5259 - val_acc: 0.3972\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0870 - acc: 0.9730 - val_loss: 4.2780 - val_acc: 0.4039\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0861 - acc: 0.9737 - val_loss: 4.5034 - val_acc: 0.4021\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0848 - acc: 0.9740 - val_loss: 4.5698 - val_acc: 0.3978\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.0839 - acc: 0.9749 - val_loss: 4.8970 - val_acc: 0.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0789 - acc: 0.9762 - val_loss: 4.6636 - val_acc: 0.3902\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.0833 - acc: 0.9755 - val_loss: 4.7275 - val_acc: 0.3930\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0806 - acc: 0.9749 - val_loss: 4.6053 - val_acc: 0.3938\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0758 - acc: 0.9781 - val_loss: 4.7149 - val_acc: 0.3813\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0780 - acc: 0.9764 - val_loss: 4.6241 - val_acc: 0.3934\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.0770 - acc: 0.9770 - val_loss: 4.7492 - val_acc: 0.3937\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0699 - acc: 0.9790 - val_loss: 4.8154 - val_acc: 0.3843\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0725 - acc: 0.9785 - val_loss: 4.5495 - val_acc: 0.4029\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0739 - acc: 0.9778 - val_loss: 4.6531 - val_acc: 0.3951\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0713 - acc: 0.9788 - val_loss: 4.6301 - val_acc: 0.3900\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3096)              1588248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3096)              9588312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               309700    \n",
      "=================================================================\n",
      "Total params: 20,706,740\n",
      "Trainable params: 20,706,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0715 - acc: 0.9799 - val_loss: 4.4242 - val_acc: 0.3969\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.0743 - acc: 0.9782 - val_loss: 4.5277 - val_acc: 0.3963\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.0675 - acc: 0.9795 - val_loss: 4.8747 - val_acc: 0.3937\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.0651 - acc: 0.9804 - val_loss: 4.6968 - val_acc: 0.3899\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0669 - acc: 0.9801 - val_loss: 4.6662 - val_acc: 0.3998\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0626 - acc: 0.9810 - val_loss: 4.6406 - val_acc: 0.3945\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0727 - acc: 0.9783 - val_loss: 4.5390 - val_acc: 0.3932\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0613 - acc: 0.9821 - val_loss: 4.4291 - val_acc: 0.3868\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0631 - acc: 0.9817 - val_loss: 4.5480 - val_acc: 0.3911\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0617 - acc: 0.9822 - val_loss: 4.5517 - val_acc: 0.3958\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0562 - acc: 0.9839 - val_loss: 4.9297 - val_acc: 0.3849\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0680 - acc: 0.9794 - val_loss: 4.4305 - val_acc: 0.3991\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0543 - acc: 0.9838 - val_loss: 4.7987 - val_acc: 0.4030\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0573 - acc: 0.9834 - val_loss: 4.8850 - val_acc: 0.3956\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0631 - acc: 0.9811 - val_loss: 4.5235 - val_acc: 0.4014\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0576 - acc: 0.9835 - val_loss: 4.5671 - val_acc: 0.3947\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0549 - acc: 0.9838 - val_loss: 4.5899 - val_acc: 0.3981\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0617 - acc: 0.9823 - val_loss: 4.6713 - val_acc: 0.3840\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0603 - acc: 0.9824 - val_loss: 4.7699 - val_acc: 0.3960\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0589 - acc: 0.9826 - val_loss: 4.9529 - val_acc: 0.3937\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0529 - acc: 0.9846 - val_loss: 4.9863 - val_acc: 0.4101\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0435 - acc: 0.9869 - val_loss: 4.9602 - val_acc: 0.3933\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0613 - acc: 0.9828 - val_loss: 4.6808 - val_acc: 0.4049\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0568 - acc: 0.9836 - val_loss: 4.7785 - val_acc: 0.4005\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0498 - acc: 0.9853 - val_loss: 5.0620 - val_acc: 0.3980\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0545 - acc: 0.9844 - val_loss: 4.5367 - val_acc: 0.4031\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0541 - acc: 0.9847 - val_loss: 4.7981 - val_acc: 0.4025\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0507 - acc: 0.9852 - val_loss: 4.7663 - val_acc: 0.3956\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0550 - acc: 0.9835 - val_loss: 4.8232 - val_acc: 0.4005\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0509 - acc: 0.9848 - val_loss: 4.7069 - val_acc: 0.3993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0509 - acc: 0.9852 - val_loss: 4.7040 - val_acc: 0.3997\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0613 - acc: 0.9827 - val_loss: 4.6036 - val_acc: 0.4005\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0402 - acc: 0.9879 - val_loss: 4.8141 - val_acc: 0.3911\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0568 - acc: 0.9842 - val_loss: 4.7160 - val_acc: 0.4077\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0532 - acc: 0.9853 - val_loss: 4.6455 - val_acc: 0.3996\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0485 - acc: 0.9858 - val_loss: 4.5476 - val_acc: 0.3975\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0522 - acc: 0.9851 - val_loss: 4.8510 - val_acc: 0.3955\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0507 - acc: 0.9851 - val_loss: 4.7079 - val_acc: 0.4051\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0481 - acc: 0.9866 - val_loss: 4.5790 - val_acc: 0.3951\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0497 - acc: 0.9860 - val_loss: 4.6405 - val_acc: 0.3975\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0489 - acc: 0.9858 - val_loss: 5.0213 - val_acc: 0.3960\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0471 - acc: 0.9867 - val_loss: 4.9009 - val_acc: 0.3993\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0440 - acc: 0.9875 - val_loss: 4.8466 - val_acc: 0.4080\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0499 - acc: 0.9854 - val_loss: 4.9593 - val_acc: 0.3974\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0473 - acc: 0.9867 - val_loss: 4.8513 - val_acc: 0.3988\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0487 - acc: 0.9858 - val_loss: 5.0947 - val_acc: 0.3955\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0474 - acc: 0.9868 - val_loss: 4.9332 - val_acc: 0.3952\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0482 - acc: 0.9861 - val_loss: 4.7727 - val_acc: 0.4083\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0450 - acc: 0.9875 - val_loss: 4.9154 - val_acc: 0.3902\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0418 - acc: 0.9882 - val_loss: 4.9384 - val_acc: 0.3966\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2596)              1331748   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2596)              6741812   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               259700    \n",
      "=================================================================\n",
      "Total params: 17,553,740\n",
      "Trainable params: 17,553,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0499 - acc: 0.9859 - val_loss: 4.5720 - val_acc: 0.3980\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0461 - acc: 0.9876 - val_loss: 4.7147 - val_acc: 0.3972\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0400 - acc: 0.9888 - val_loss: 4.7882 - val_acc: 0.3986\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0462 - acc: 0.9867 - val_loss: 4.9383 - val_acc: 0.4045\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0484 - acc: 0.9871 - val_loss: 5.2911 - val_acc: 0.3897\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0482 - acc: 0.9867 - val_loss: 4.7604 - val_acc: 0.4018\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0488 - acc: 0.9866 - val_loss: 4.7345 - val_acc: 0.4012\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0410 - acc: 0.9890 - val_loss: 5.0671 - val_acc: 0.4016\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0437 - acc: 0.9877 - val_loss: 4.9764 - val_acc: 0.4030\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0346 - acc: 0.9900 - val_loss: 5.2151 - val_acc: 0.3983\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0522 - acc: 0.9863 - val_loss: 5.0177 - val_acc: 0.3959\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0489 - acc: 0.9870 - val_loss: 4.8451 - val_acc: 0.3965\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0426 - acc: 0.9883 - val_loss: 5.1248 - val_acc: 0.3920\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0459 - acc: 0.9882 - val_loss: 5.0696 - val_acc: 0.3900\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0417 - acc: 0.9887 - val_loss: 5.1134 - val_acc: 0.3872\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0411 - acc: 0.9892 - val_loss: 4.7663 - val_acc: 0.3957\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0424 - acc: 0.9883 - val_loss: 5.0380 - val_acc: 0.3956\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0480 - acc: 0.9879 - val_loss: 4.9961 - val_acc: 0.3989\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.0433 - acc: 0.9884 - val_loss: 4.5833 - val_acc: 0.4018\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0364 - acc: 0.9897 - val_loss: 5.0028 - val_acc: 0.3927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0417 - acc: 0.9886 - val_loss: 4.8972 - val_acc: 0.3972\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0429 - acc: 0.9883 - val_loss: 4.7710 - val_acc: 0.3969\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0472 - acc: 0.9874 - val_loss: 4.9261 - val_acc: 0.3969\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0404 - acc: 0.9889 - val_loss: 5.0898 - val_acc: 0.3879\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0454 - acc: 0.9877 - val_loss: 5.0672 - val_acc: 0.4009\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0362 - acc: 0.9899 - val_loss: 5.1409 - val_acc: 0.4000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0428 - acc: 0.9882 - val_loss: 5.4012 - val_acc: 0.3891\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0423 - acc: 0.9886 - val_loss: 4.8155 - val_acc: 0.4020\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0429 - acc: 0.9889 - val_loss: 5.1833 - val_acc: 0.3974\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0390 - acc: 0.9897 - val_loss: 4.9167 - val_acc: 0.3994\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0388 - acc: 0.9899 - val_loss: 5.2292 - val_acc: 0.3966\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0437 - acc: 0.9880 - val_loss: 5.0819 - val_acc: 0.3955\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0383 - acc: 0.9894 - val_loss: 4.7226 - val_acc: 0.3945\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0402 - acc: 0.9890 - val_loss: 4.8774 - val_acc: 0.3990\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0370 - acc: 0.9903 - val_loss: 4.9313 - val_acc: 0.4047\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0393 - acc: 0.9896 - val_loss: 5.0135 - val_acc: 0.3968\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0554 - acc: 0.9856 - val_loss: 4.8498 - val_acc: 0.4023\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0348 - acc: 0.9905 - val_loss: 4.8939 - val_acc: 0.4069\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0335 - acc: 0.9907 - val_loss: 4.8131 - val_acc: 0.4047\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0435 - acc: 0.9884 - val_loss: 4.7795 - val_acc: 0.3970\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0383 - acc: 0.9895 - val_loss: 5.0340 - val_acc: 0.3974\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0383 - acc: 0.9900 - val_loss: 5.2253 - val_acc: 0.3952\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0379 - acc: 0.9897 - val_loss: 4.8800 - val_acc: 0.3992\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0372 - acc: 0.9895 - val_loss: 5.0242 - val_acc: 0.3937\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0374 - acc: 0.9896 - val_loss: 5.1229 - val_acc: 0.3947\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0448 - acc: 0.9884 - val_loss: 4.7972 - val_acc: 0.3999\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0318 - acc: 0.9912 - val_loss: 5.1435 - val_acc: 0.4050\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0478 - acc: 0.9886 - val_loss: 4.8303 - val_acc: 0.4040\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0393 - acc: 0.9902 - val_loss: 4.8449 - val_acc: 0.4033\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0402 - acc: 0.9900 - val_loss: 5.0357 - val_acc: 0.3937\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2096)              1075248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2096)              4395312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               209700    \n",
      "=================================================================\n",
      "Total params: 14,900,740\n",
      "Trainable params: 14,900,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0369 - acc: 0.9900 - val_loss: 5.3304 - val_acc: 0.3928\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0363 - acc: 0.9904 - val_loss: 5.0257 - val_acc: 0.4018\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0382 - acc: 0.9896 - val_loss: 5.2784 - val_acc: 0.4029\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0406 - acc: 0.9896 - val_loss: 5.1102 - val_acc: 0.3960\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0416 - acc: 0.9887 - val_loss: 5.0746 - val_acc: 0.3882\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0369 - acc: 0.9898 - val_loss: 5.1347 - val_acc: 0.3981\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0359 - acc: 0.9905 - val_loss: 5.2996 - val_acc: 0.3981\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0394 - acc: 0.9899 - val_loss: 4.8580 - val_acc: 0.3917\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0422 - acc: 0.9893 - val_loss: 5.0480 - val_acc: 0.4014\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0331 - acc: 0.9917 - val_loss: 5.2298 - val_acc: 0.3969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0393 - acc: 0.9900 - val_loss: 5.1637 - val_acc: 0.4067\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0445 - acc: 0.9883 - val_loss: 5.1425 - val_acc: 0.3933\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0411 - acc: 0.9898 - val_loss: 4.7192 - val_acc: 0.4063\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0217 - acc: 0.9941 - val_loss: 5.2359 - val_acc: 0.4043\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0468 - acc: 0.9878 - val_loss: 4.6807 - val_acc: 0.3992\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0303 - acc: 0.9926 - val_loss: 5.2413 - val_acc: 0.3992\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0475 - acc: 0.9884 - val_loss: 5.0327 - val_acc: 0.3949\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0324 - acc: 0.9914 - val_loss: 5.1473 - val_acc: 0.3990\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0389 - acc: 0.9900 - val_loss: 5.0716 - val_acc: 0.4013\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0362 - acc: 0.9913 - val_loss: 5.0488 - val_acc: 0.4030\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0401 - acc: 0.9896 - val_loss: 5.0248 - val_acc: 0.3995\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0358 - acc: 0.9909 - val_loss: 5.5139 - val_acc: 0.3976\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0425 - acc: 0.9893 - val_loss: 5.0228 - val_acc: 0.3936\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0330 - acc: 0.9917 - val_loss: 5.3476 - val_acc: 0.3943\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0384 - acc: 0.9902 - val_loss: 5.0121 - val_acc: 0.4035\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0392 - acc: 0.9909 - val_loss: 5.3415 - val_acc: 0.4014\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0447 - acc: 0.9892 - val_loss: 5.0429 - val_acc: 0.3989\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0313 - acc: 0.9922 - val_loss: 5.2691 - val_acc: 0.4019\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0348 - acc: 0.9914 - val_loss: 5.0508 - val_acc: 0.3970\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0354 - acc: 0.9912 - val_loss: 5.0169 - val_acc: 0.3990\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0345 - acc: 0.9913 - val_loss: 5.0146 - val_acc: 0.4036\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0438 - acc: 0.9889 - val_loss: 5.1823 - val_acc: 0.3959\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0425 - acc: 0.9901 - val_loss: 4.8870 - val_acc: 0.4021\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0283 - acc: 0.9927 - val_loss: 4.9643 - val_acc: 0.4015\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0364 - acc: 0.9908 - val_loss: 5.2709 - val_acc: 0.3989\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.0393 - acc: 0.9911 - val_loss: 4.7889 - val_acc: 0.4054\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0372 - acc: 0.9911 - val_loss: 4.8350 - val_acc: 0.3933\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0333 - acc: 0.9918 - val_loss: 5.1998 - val_acc: 0.4001\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0416 - acc: 0.9895 - val_loss: 4.9287 - val_acc: 0.3890\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0370 - acc: 0.9911 - val_loss: 4.9927 - val_acc: 0.3977\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0374 - acc: 0.9911 - val_loss: 4.8497 - val_acc: 0.4034\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0329 - acc: 0.9919 - val_loss: 4.7819 - val_acc: 0.4043\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0314 - acc: 0.9922 - val_loss: 5.0438 - val_acc: 0.4008\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0345 - acc: 0.9913 - val_loss: 4.9316 - val_acc: 0.4023\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0355 - acc: 0.9914 - val_loss: 4.8651 - val_acc: 0.3971\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0384 - acc: 0.9905 - val_loss: 4.9592 - val_acc: 0.4074\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0257 - acc: 0.9930 - val_loss: 5.2816 - val_acc: 0.4026\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0432 - acc: 0.9898 - val_loss: 5.0678 - val_acc: 0.3971\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0420 - acc: 0.9903 - val_loss: 5.0022 - val_acc: 0.3872\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0272 - acc: 0.9930 - val_loss: 5.2107 - val_acc: 0.4021\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1596)              818748    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1596)              2548812   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               159700    \n",
      "=================================================================\n",
      "Total params: 12,747,740\n",
      "Trainable params: 12,747,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 24s 470us/step - loss: 0.0300 - acc: 0.9925 - val_loss: 5.3646 - val_acc: 0.4020\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0410 - acc: 0.9902 - val_loss: 5.2426 - val_acc: 0.4013\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0341 - acc: 0.9917 - val_loss: 5.2690 - val_acc: 0.3976\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0328 - acc: 0.9925 - val_loss: 4.9334 - val_acc: 0.3980\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0438 - acc: 0.9901 - val_loss: 5.1336 - val_acc: 0.4006\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0371 - acc: 0.9912 - val_loss: 5.2267 - val_acc: 0.3978\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0427 - acc: 0.9898 - val_loss: 4.8196 - val_acc: 0.4077\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0232 - acc: 0.9939 - val_loss: 5.2964 - val_acc: 0.3992\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0378 - acc: 0.9910 - val_loss: 5.0416 - val_acc: 0.3996\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0392 - acc: 0.9910 - val_loss: 5.0328 - val_acc: 0.3956\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0394 - acc: 0.9907 - val_loss: 5.1149 - val_acc: 0.4024\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0324 - acc: 0.9918 - val_loss: 5.2480 - val_acc: 0.4047\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0315 - acc: 0.9924 - val_loss: 5.1917 - val_acc: 0.3966\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0314 - acc: 0.9928 - val_loss: 5.2843 - val_acc: 0.4029\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0350 - acc: 0.9914 - val_loss: 5.3306 - val_acc: 0.3997\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0312 - acc: 0.9928 - val_loss: 5.3947 - val_acc: 0.4006\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0397 - acc: 0.9910 - val_loss: 5.0071 - val_acc: 0.3999\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0321 - acc: 0.9920 - val_loss: 5.1984 - val_acc: 0.3989\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0422 - acc: 0.9906 - val_loss: 5.2897 - val_acc: 0.3959\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0317 - acc: 0.9930 - val_loss: 4.9801 - val_acc: 0.4076\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0364 - acc: 0.9913 - val_loss: 4.9807 - val_acc: 0.4034\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0368 - acc: 0.9913 - val_loss: 5.0567 - val_acc: 0.4012\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0258 - acc: 0.9940 - val_loss: 5.4224 - val_acc: 0.3981\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0358 - acc: 0.9919 - val_loss: 5.4000 - val_acc: 0.3958\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0498 - acc: 0.9894 - val_loss: 4.7352 - val_acc: 0.4006\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0373 - acc: 0.9913 - val_loss: 5.3555 - val_acc: 0.3957\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0329 - acc: 0.9924 - val_loss: 5.1749 - val_acc: 0.4032\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0301 - acc: 0.9928 - val_loss: 5.0986 - val_acc: 0.4001\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0375 - acc: 0.9916 - val_loss: 5.0455 - val_acc: 0.3949\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0392 - acc: 0.9907 - val_loss: 5.0190 - val_acc: 0.3992\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0312 - acc: 0.9927 - val_loss: 5.1612 - val_acc: 0.3982\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0406 - acc: 0.9913 - val_loss: 5.3182 - val_acc: 0.3944\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0396 - acc: 0.9915 - val_loss: 5.0106 - val_acc: 0.4000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0411 - acc: 0.9910 - val_loss: 4.9780 - val_acc: 0.4053\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0329 - acc: 0.9922 - val_loss: 5.5477 - val_acc: 0.4038\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0368 - acc: 0.9922 - val_loss: 4.9177 - val_acc: 0.4045\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0378 - acc: 0.9916 - val_loss: 5.0387 - val_acc: 0.4009\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0191 - acc: 0.9950 - val_loss: 5.2072 - val_acc: 0.4012\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0354 - acc: 0.9917 - val_loss: 5.0894 - val_acc: 0.4043\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.0319 - acc: 0.9927 - val_loss: 5.0096 - val_acc: 0.4065\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0344 - acc: 0.9919 - val_loss: 5.0423 - val_acc: 0.4063\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0347 - acc: 0.9924 - val_loss: 4.8375 - val_acc: 0.4039\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0314 - acc: 0.9921 - val_loss: 5.2432 - val_acc: 0.4008\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0463 - acc: 0.9901 - val_loss: 5.1421 - val_acc: 0.3959\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0261 - acc: 0.9942 - val_loss: 5.3530 - val_acc: 0.4020\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0419 - acc: 0.9907 - val_loss: 5.3162 - val_acc: 0.3971\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0351 - acc: 0.9921 - val_loss: 5.0324 - val_acc: 0.4038\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0319 - acc: 0.9930 - val_loss: 4.8717 - val_acc: 0.4005\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0328 - acc: 0.9927 - val_loss: 5.1994 - val_acc: 0.3985\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0294 - acc: 0.9931 - val_loss: 5.3504 - val_acc: 0.3982\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1096)              562248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1096)              1202312   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               109700    \n",
      "=================================================================\n",
      "Total params: 11,094,740\n",
      "Trainable params: 11,094,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0310 - acc: 0.9928 - val_loss: 5.1244 - val_acc: 0.3958\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0335 - acc: 0.9920 - val_loss: 5.1980 - val_acc: 0.4033\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0301 - acc: 0.9925 - val_loss: 5.1978 - val_acc: 0.4008\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0298 - acc: 0.9937 - val_loss: 5.1171 - val_acc: 0.3985\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0363 - acc: 0.9916 - val_loss: 5.2606 - val_acc: 0.3917\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0306 - acc: 0.9934 - val_loss: 5.0754 - val_acc: 0.4014\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0271 - acc: 0.9939 - val_loss: 5.1633 - val_acc: 0.4037\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0305 - acc: 0.9931 - val_loss: 5.2792 - val_acc: 0.4006\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0404 - acc: 0.9909 - val_loss: 5.1497 - val_acc: 0.3915\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0385 - acc: 0.9916 - val_loss: 5.3510 - val_acc: 0.4001\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0324 - acc: 0.9932 - val_loss: 5.6403 - val_acc: 0.3915\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0344 - acc: 0.9924 - val_loss: 5.1611 - val_acc: 0.3975\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.0375 - acc: 0.9914 - val_loss: 5.2725 - val_acc: 0.3958\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0314 - acc: 0.9928 - val_loss: 5.2530 - val_acc: 0.4002\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0332 - acc: 0.9929 - val_loss: 5.2182 - val_acc: 0.3901\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0350 - acc: 0.9920 - val_loss: 5.2784 - val_acc: 0.3954\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0216 - acc: 0.9947 - val_loss: 5.2874 - val_acc: 0.3978\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0292 - acc: 0.9941 - val_loss: 5.2557 - val_acc: 0.3908\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0498 - acc: 0.9889 - val_loss: 5.4786 - val_acc: 0.3924\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0318 - acc: 0.9926 - val_loss: 5.0798 - val_acc: 0.3922\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0293 - acc: 0.9931 - val_loss: 4.9457 - val_acc: 0.4025\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0286 - acc: 0.9932 - val_loss: 5.6605 - val_acc: 0.3907\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0349 - acc: 0.9924 - val_loss: 5.5780 - val_acc: 0.3949\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0358 - acc: 0.9922 - val_loss: 4.9374 - val_acc: 0.4088\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0253 - acc: 0.9940 - val_loss: 5.2048 - val_acc: 0.3950\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0333 - acc: 0.9921 - val_loss: 5.5178 - val_acc: 0.3975\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0299 - acc: 0.9935 - val_loss: 5.4520 - val_acc: 0.3944\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.0422 - acc: 0.9912 - val_loss: 5.3334 - val_acc: 0.4038\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 0.0343 - acc: 0.9923 - val_loss: 5.7005 - val_acc: 0.3954\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0291 - acc: 0.9933 - val_loss: 5.4047 - val_acc: 0.4014\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0270 - acc: 0.9943 - val_loss: 5.0514 - val_acc: 0.4039\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0408 - acc: 0.9908 - val_loss: 5.2724 - val_acc: 0.4015\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0332 - acc: 0.9928 - val_loss: 5.2409 - val_acc: 0.4029\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0308 - acc: 0.9933 - val_loss: 5.3245 - val_acc: 0.4035\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0355 - acc: 0.9921 - val_loss: 5.1406 - val_acc: 0.4020\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0326 - acc: 0.9927 - val_loss: 5.4899 - val_acc: 0.4039\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0380 - acc: 0.9917 - val_loss: 5.3978 - val_acc: 0.3994\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0271 - acc: 0.9941 - val_loss: 5.3561 - val_acc: 0.3980\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.0357 - acc: 0.9926 - val_loss: 5.3647 - val_acc: 0.3997\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0367 - acc: 0.9924 - val_loss: 5.5365 - val_acc: 0.4021\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0300 - acc: 0.9937 - val_loss: 5.1968 - val_acc: 0.3957\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.0312 - acc: 0.9929 - val_loss: 5.3720 - val_acc: 0.4043\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.0374 - acc: 0.9920 - val_loss: 5.2573 - val_acc: 0.4038\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.0410 - acc: 0.9916 - val_loss: 5.1722 - val_acc: 0.3998\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.0275 - acc: 0.9940 - val_loss: 5.2508 - val_acc: 0.3936\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0295 - acc: 0.9938 - val_loss: 5.3156 - val_acc: 0.4043\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.0241 - acc: 0.9945 - val_loss: 5.8247 - val_acc: 0.4009\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.0427 - acc: 0.9907 - val_loss: 5.2198 - val_acc: 0.4005\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0287 - acc: 0.9935 - val_loss: 5.1094 - val_acc: 0.3925\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.0408 - acc: 0.9918 - val_loss: 5.3116 - val_acc: 0.4034\n"
     ]
    }
   ],
   "source": [
    "cifar100_accu = 0.4042\n",
    "params_count_layer100, min_val_loss_layer100, min_val_acc100 = modified_fcn_vggA(X_train100, y_train100, X_val100, y_val100, decrement=500,\n",
    "                                              input_shape=(32, 32, 3), classes=100, epoch=50, batch_size=64, \n",
    "                                              early_stop=False, verbose=1, compa=cifar100_accu)\n",
    "\n",
    "np.savetxt(r\"fcn_cifar100\" + \".txt\", np.asmatrix([params_count_layer100, min_val_loss_layer100, min_val_acc100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_count_layer10, min_val_loss_layer10, min_val_acc10 = np.loadtxt(\"fcn_cifar10.txt\")\n",
    "params_count_layer100, min_val_loss_layer100, min_val_acc100 = np.loadtxt('fcn_cifar100.txt')\n",
    "\n",
    "\n",
    "# Plot out the results\n",
    "filter_range = range(4096-500, 596, -500)\n",
    "\n",
    "cifar10_bar = np.copy(filter_range)\n",
    "cifar10_bar[:] = 75.2\n",
    "cifar100_bar = np.copy(filter_range)\n",
    "cifar100_bar[:] = 40.42\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.set_title(\"CIFAR-10\")\n",
    "h = plt.plot(filter_range, min_val_loss_layer10, \"r-+\", linewidth=2)\n",
    "plt.xlabel('# of Filters in Each FCN Layer')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.xlim([filter_range[0], filter_range[-1]])\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.set_title(\"CIFAR-100\")\n",
    "h = plt.plot(filter_range, min_val_loss_layer100, \"b-*\", linewidth=2)\n",
    "plt.xlabel('# of Filters in Each FCN Layer')\n",
    "plt.xlim([filter_range[0], filter_range[-1]])\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "h = plt.plot(filter_range, cifar10_bar, \"g\", linewidth=0.5)\n",
    "h = plt.plot(filter_range, min_val_acc10*100, \"r-+\", linewidth=2)\n",
    "plt.legend(['Original Accuracy'])\n",
    "plt.xlabel('# of Filters in Each FCN Layer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim([filter_range[0], filter_range[-1]])\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "h = plt.plot(filter_range, cifar100_bar, \"g\", linewidth=0.5)\n",
    "h = plt.plot(filter_range, min_val_acc100*100, \"b-*\", linewidth=2)\n",
    "plt.legend(['Original Accuracy'])\n",
    "plt.xlabel('# of Filters in Each FCN Layer')\n",
    "plt.xlim([filter_range[0], filter_range[-1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Opposed to our speculation, it turns out that removing the convolutional layers will improve the model more than removing the FCN layers. In these figures, even though the model is less overfitting than the original one, the improvement in accuracy is not as clear as when we remove convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Part 4, state of the art\n",
    "\n",
    "Currently, state of the art implementations in the image classification problem are DenseNet: (https://arxiv.org/abs/1608.06993), ResNet (https://arxiv.org/abs/1512.03385), and ResNext (https://arxiv.org/pdf/1611.05431.pdf). Try implementing and training one of these on the cifar10 and cifar100 dataset. Feel free to experiment.\n",
    "\n",
    "Jargon to learn about\n",
    "1. What is \"residual learning\"?\n",
    "2. What is a \"bottleneck layer\"?\n",
    "3. What is a \"dense block\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
